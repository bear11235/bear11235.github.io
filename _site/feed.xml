<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-04-28T17:07:51+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">bear11235’s blog</title><subtitle>bear11235&apos;s study blog. </subtitle><author><name>bear11235</name></author><entry><title type="html">[ML/DL] Gaussian Process 공부하기</title><link href="http://localhost:4000/study/ml-dl/gaussian-process/" rel="alternate" type="text/html" title="[ML/DL] Gaussian Process 공부하기" /><published>2023-04-28T00:00:00+09:00</published><updated>2023-04-28T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/gaussian-process</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/gaussian-process/"><![CDATA[<h1 id="learning">Learning</h1>

<h2 id="log-likelihood-of-mvn">Log-Likelihood of MVN</h2>
<p>GP를 실제 데이터에 적용하면 우리가 얻게되는 데이터의 형태는 Multi-Variate Normal(MVN) 분포를 따르게 된다. n차원의 MVN 분포를 생각해보자. 평균은 n차원의 벡터로, 공분산은 \(n \times n\)의 행렬로 표현된다.</p>

\[\mathbf{X}\sim \mathcal{N_n}(\mathbf{\mu}, \mathbf{\Sigma}) \quad \text{where} \quad \mathbf{\mu} \in \mathcal{R}^n, \mathbf{\Sigma} \in \mathcal{R}^{n \times n}\]

<p>그리고 위 분포의 pdf는 아래와 같이 정의된다.</p>

\[p(\mathbf{x; \mu, \Sigma}) = (2 \pi)^{-n/2} \det{(\mathbf{\Sigma})}^{-1/2} \exp{\left(-\frac{1}{2} \mathbf{(x-\mu)^T \Sigma^{-1} (x-\mu)}\right)}\]

<p>평균과 공분산을 파라미터 \(\mathbf{\Theta}\)로 생각하면 log-likelihood 함수를 아래와 같이 계산할 수 있다.</p>

\[\mathcal{L}(\mathbf{\Theta}) = \log p(\mathbf{x}; \mathbf{\Theta}) = 
-\frac{n}{2}\log(2\pi) -\frac{1}{2}\det{\mathbf{\Sigma}} -\frac{1}{2} \mathbf{(x-\mu)^T \Sigma^{-1} (x-\mu)}\]

<p>만약 prior mean을 0으로 생각한다면 조금 단순해진다.</p>

\[\mathcal{L}(\mathbf{\Theta}) = -\frac{n}{2}\log(2\pi) -\frac{1}{2}\det{\mathbf{\Sigma}} -\frac{1}{2} \mathbf{x^T \Sigma^{-1} x}\]

<h2 id="marginal-log-likelihood-in-gp">Marginal Log-Likelihood in GP</h2>
<p>Gaussian Process는 프로세스 안에서 어떠한 subset을 골라도 gaussian distribution을 따르기 때문에, 우리가 관심있는 index에 대해서 marginalize하기 쉽다. 이를 Marginal Log-Likelihood(MLL)이라 하자. GP를 통해 찾고자하는 latent function variable(?) 혹은 참이라고 추정하는 함수값을 \(\mathbf{f}\)라고 하자. 실제 그 함수가 우리에게 발현되어 관측되는 값은 노이즈가 섞인 값이다. 관측되는 값을 \(\mathbf{y}\)라고 하자. 우리가 학습하는 과정에서 활용하는 데이터는 실제 측정된 데이터이므로 \(\mathbf{f}\)보단 \(\mathbf{y}\)라고 생각해야 한다. 따라서 우리가 구하고자 하는 likelihood 값은 아래와 같다. GP를 학습하기 위해서 위 MLL 값을 최대화, 혹은 negative MLL을 최소화한다.</p>

\[\begin{align}
\mathcal{L}(\mathbf{\Theta}) &amp;= p(\mathbf{y}\vert\mathbf{x}; \mathbf{\Theta}) \\
&amp;= \int{p(\mathbf{y \vert f}) p(\mathbf{f \vert x}) d\mathbf{f}} \\
&amp;= -\frac{n}{2}\log(2\pi) -\frac{1}{2}\log(\det{(\mathbf{\Sigma} + \sigma_n^2\mathbf{I})}) -\frac{1}{2} \mathbf{x^T (\mathbf{\Sigma} + \sigma_n^2\mathbf{I})^{-1} x} \\
&amp;= -\frac{n}{2}\log(2\pi) -\frac{1}{2}\log(\det{\mathbf{\Sigma'}}) -\frac{1}{2} \mathbf{x^T (\Sigma')^{-1} x}
\end{align}\]

<p>MLL을 계산할 때, Covariance Matrix가 가진 성질을 바탕으로 Cholesky decomposition을 활용해 직접 역행렬과 행렬식을 구하는 것보다 빠르게 구할 수 있다. Symmetric Semi-Positive Definite Matrix \(K\)에 대해서 아래와 같은 cholesky decomposition이 가능하다.</p>

\[K = LL^T = L^TL  \quad \text{where} \quad L \text{ is triangular matrix}\]

<p>우리가 다루는 Covariance Matrix는 위 조건을 만족하므로 cholesky decomposition이 가능하고, 위에서 정리한 MLL은 아래와 같이 전개된다.</p>

\[\begin{align}
\mathcal{L} &amp;\propto -\frac{1}{2}\log(\det{\mathbf{\Sigma'}}) -\frac{1}{2} \mathbf{y^T (\Sigma')^{-1} y} \\
&amp;= -\frac{1}{2}\log(\det{(\mathbf{L L}^T)}) -\frac{1}{2} \mathbf{y^T L^{-T} L^{-1} y} \\
&amp;= -\log(\det{\mathbf{L}}) -\frac{1}{2} \mathbf{y^T L^{-T} L^{-1} y} \\
&amp;= -\sum_{i=1}^{n} \log L_{ii} -\frac{1}{2} \mathbf{\alpha}^T \mathbf{\alpha}, \qquad \text{where } \alpha =\mathbf{L}\backslash\mathbf{y}\\
\end{align}\]]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="Gaussian Process" /><category term="GP" /><summary type="html"><![CDATA[Learning]]></summary></entry><entry><title type="html">Remote access with SSH tunneling</title><link href="http://localhost:4000/linux/cluster/remote-access-via-ssh-tunneling/" rel="alternate" type="text/html" title="Remote access with SSH tunneling" /><published>2023-04-23T00:00:00+09:00</published><updated>2023-04-23T00:00:00+09:00</updated><id>http://localhost:4000/linux/cluster/remote-access-via-ssh-tunneling</id><content type="html" xml:base="http://localhost:4000/linux/cluster/remote-access-via-ssh-tunneling/"><![CDATA[]]></content><author><name>bear11235</name></author><category term="linux" /><category term="cluster" /><category term="linux" /><category term="cluster" /><category term="firewall" /><category term="ssh" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Explainable AI (LIME, SHAP) 공부하기</title><link href="http://localhost:4000/study/ml-dl/explainable-AI/" rel="alternate" type="text/html" title="Explainable AI (LIME, SHAP) 공부하기" /><published>2023-04-23T00:00:00+09:00</published><updated>2023-04-23T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/explainable-AI</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/explainable-AI/"><![CDATA[<p>AI의 모델</p>
<ul>
  <li>Rule-based system: 사람이 일일이 프로그램하여 컴퓨터는 주어진 규칙대로 계산만 수행.</li>
  <li>Classic ML-DL: 사람이 feature를 디자인하고, 컴퓨터는 feature를 매핑한다.</li>
  <li>Deep Learning: 더욱 복잡한 feature를 모델이 찾는다.</li>
</ul>

<p>일반적으로 explainability가 높다는 것은 모델의 complexity가 낮다는 것이고, 이는 모델의 capacity or performance가 낮음을 의미한다. 그래서 복잡한 DL의 경우, black-box처럼 생각되는 경우가 많다.</p>

<p>Need for explainable AI</p>
<ul>
  <li>Explain to Justify: 시스템의 행동 이유에 대한 정당성.</li>
  <li>Explain to Improve: 시스템의 성능 개선을 위해서.</li>
  <li>Explain to Discover: DL은 사람이 찾지 못하는 패턴들을 잘 찾는다. 그 패턴을 이해하기 위해.</li>
  <li>Explain to Control: 모델의 적절한 제어를 위해.</li>
</ul>

<p>설명가능한 AI를 통해 아래의 질문에 답하고자 함.</p>
<ul>
  <li>왜 그렇게 했는지?</li>
  <li>왜 다른 행동은 안 했는지?</li>
  <li>언제 성공/실패를 하는지?</li>
  <li>언제 결과를 신뢰해도 괜찮은지?</li>
  <li>어떻게 에러를 수정할지?</li>
</ul>

<h1 id="설명-가능성의-종류">설명 가능성의 종류</h1>
<h2 id="설명-가능함의-시점">설명 가능함의 시점</h2>
<ul>
  <li>Ante-hoc (build a new learning model)
    <ul>
      <li>모델을 만들 때부터 설명가능하게끔 만든다.</li>
    </ul>
  </li>
  <li>Post-hoc (explain the black-box)
    <ul>
      <li>블랙박스 형태의 모델을 생성한 후에, 그 블랙박스 모델을 새로운 방식을 통해 설명하고자 함.</li>
    </ul>
  </li>
</ul>

<h2 id="모델-제한적">모델 제한적</h2>
<ul>
  <li>Model-specific
    <ul>
      <li>어떤 구체적인 아키텍쳐의 모델에 대해 사용 가능</li>
      <li>모델 자체가 설명 가능함을 지닌 경우</li>
      <li>어떤 경우에는 모델 성능에 영향을 준다.</li>
    </ul>
  </li>
  <li>Model-agnostic
    <ul>
      <li>일반적인 블랙박스 모델에 사용 가능</li>
      <li>기존 모델은 그대로 두고, 추후 설명 가능함을 위한 모듈을 추가하는 형식이라 블랙박스 모델 성능에 영향을 주지 않음.</li>
    </ul>
  </li>
</ul>

<h2 id="국지성">국지성</h2>
<ul>
  <li>Global interpretability
    <ul>
      <li>모델 전체를 보고, 해당 모델이 전반적으로 어떤 행동을 할지 설명 가능함.</li>
      <li>예를 들어, decisition tree를 보면 전체적인 모델의 행동 양상이 보인다.</li>
    </ul>
  </li>
  <li>Local interpretability
    <ul>
      <li>어떤 입력값에 대한 모델의 결과를 설명 가능함.</li>
      <li>예를 들어 복잡한 사진을 주고 물체를 구분하는 작업에서 사진 내 픽셀에 대한 각 카테고리 별 확률 분포 제시.</li>
    </ul>
  </li>
</ul>

<p><strong>Sensitivity Analysis (SA)</strong></p>

<p>모델에 영향을 많이 주는 입력값은, 출력값을 입력값으로 미분했을 때, gradient 값이 큰 입력값이다. 예를 들어 모델에 사진을 넣었고, 모델은 고양이라는 답을 주었다면 그 답에 영향을 많이 미치는 입력 픽셀은 큰 gradient를 가질 것이다(?) 진짜 그럴려나.. 만약 사진을 입력으로 넣은 경우를 생각해보자. 사진을 보고 카테고리를 분류하는 모델이 어떤 한 사진을 입력으로 받고 고양이라는 답을 내놓았다. 모델의 출력에 x라는 점들이 영향을 가장 크게 주었다면, 만약 x 점들이 이상한 값으로 될 경우, 모델이 고양이라는 답을 내놓지 않을 것이다.</p>

<p><strong>Layerwise Relevance Propagation (LRP)</strong></p>

<p>어떤 결과가 나왔을 때, 입력값을 기준으로 얼마나 contribution이 있는지 역추적하는 느낌? FCNN을 생각해볼 때, 마지막 hidden layer 내 노드 중, 출력값에 가장 큰 영향을 주는 노드를 찾을 수 있을 것이다. 또 해당 layer에 영향을 주는 정도를 이전 layer의 노드들에 대해 계산할 수 있을 것이고 이를 반복적으로 할 수 있을 것이다. 그렇게 출력값에 대한 입력값의 기여도를 계산할 수 있다.</p>

<h1 id="lime">LIME</h1>
<p>Local Interpretable Model-agnostic Explanations</p>

<p>예시를 먼저 보자. 어떤 모델이 sneeze, weight, headache, no fatigue, age의 feature를 보고 flu를 판단한다고 하자. LIME이 하고 싶은 것은 flu라는 답에 대해 어떤 features가 얼마나 영향을 끼쳤는지를 보는 것이다.</p>

<p>LIME은 다음 4개의 basic criteria를 만족해야 함:</p>
<ol>
  <li>Interpretable: 쉽게 설명 가능해야 한다.</li>
  <li>Local fidelity: 임의의 instance에 대해서 설명을 할 때, local behavior를 잘 설명해야 한다.</li>
  <li>Model-agnostic: 임의의 모델에 대해 잘 작동해야 한다.</li>
  <li>Global perspective: 전체적인 거동도 어느 정도 설명해야 한다(?)</li>
</ol>

<h1 id="shap">SHAP</h1>
<p>SHapley Additive exPlanation의 약자.</p>

<h2 id="shapley-value">Shapley Value</h2>
<p>게임 이론에서 등장하는 개념. Total payout을 도출하기 위한 각 개인의 기여도를 계산하는 방식. 예를 들어 A,B가 팀 과제를 하는 상황이다. A 혼자하면 70점을 맞고, B 혼자하면 80점을 맞고, A와 B가 같이 하면 100점을 맞는다고 하자. 둘이 같이 하여 100점을 맞았을 때 A, B의 기여도는 어떻게 되는 것인가? 이러한 질문에 사용되는 개념이다. 출력값에 대한 입력값의 영향이 비선형적으로 결합이 될텐데, 그것을 decompostion하는 방식이라고 보면 좋을 듯.</p>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="AI" /><category term="LIME" /><category term="SHAP" /><summary type="html"><![CDATA[AI의 모델 Rule-based system: 사람이 일일이 프로그램하여 컴퓨터는 주어진 규칙대로 계산만 수행. Classic ML-DL: 사람이 feature를 디자인하고, 컴퓨터는 feature를 매핑한다. Deep Learning: 더욱 복잡한 feature를 모델이 찾는다.]]></summary></entry><entry><title type="html">t-SNE 공부하기</title><link href="http://localhost:4000/study/ml-dl/SNE/" rel="alternate" type="text/html" title="t-SNE 공부하기" /><published>2023-04-22T00:00:00+09:00</published><updated>2023-04-22T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/SNE</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/SNE/"><![CDATA[<h1 id="sne">SNE</h1>
<p>Stochastic Neighbor Embedding의 약자. 여기서 임베딩의 의미는 고차원에서 저차원으로 매핑한다는 말이다.</p>

<p>고차원 공간에 있는 데이터 포인트들 사이의 거리, 혹은 이웃인 정도를 확률로서 표현하고, 그 확률을 유지하도록 저차원 공간으로 매핑하는 것. 데이터 자체는 왜곡이 될 수 있지만, 데이터 사이의 가까운 정도는 최대한 유지하고 싶다. 여기서 학습이라는 것은 고차원 공간에서 저차원 공간으로 매핑하는 방법을 학습하는 것.</p>

<p>고차원에서 이웃의 정도를 결정하는 방법? -&gt; Squared Exponential 함수를 통해 거리를 측정하고 확률로 표현하기 위해서 normalize를 진행한다. n개의 데이터 포인트에 대해서 각각 n개의 데이터에 대한 이웃인 정도를 나타내기에 n by n 형태의 Neighbar Probability Matrix가 생성된다. 각 데이터 포인트 사이의 절대적 거리는 대칭적이지만, 기준이 되는 포인트에서 normalization constant는 다르기 때문에, probability matrix는 비대칭으로 표현될 수 있다.</p>

<h2 id="perplexity">Perplexity</h2>
<p>2 ** H(P_i)로 정의된다. 데이터끼리 뭉치고 흩어지는 정도를 정하는 파라미터. 대략 한 점에서 이웃이라고 생각하는 점의 개수라고 생각하면 될 듯.</p>

<h2 id="cost-function">Cost Function</h2>
<p>고차원과 저차원에서의 확률 행렬을 각각 P_ij, Q_ij라고 하면, 그 둘 사이의 차이값, 거리값, 괴리감은 확률 분포의 괴리를 표현하는 KL divergence로 표현한다.</p>

\[J = KL(P||Q)\]

<p>KL Divergence를 사용하면, gradient descent 방식에서 식이 쉽게 나온다.</p>

\[dJ/dy = sth\]

<p>gradient의 의미는? 이웃인 확률이 고차원 &gt; 저차원 이라면 저차원 공간에서 서로 가까이 당겨야하고, 반대로 고차원 &lt; 저차원 이라면 저차원 공간에서 서로 밀어야 한다. 또한 gradient의 크기가 저차원에서의 거리에 비례하기 때문에, 학습 과정에서 저차원 공간으로 매핑된 데이터들이 서로 뭉치게 된다.</p>

<p>실제 데이터들을 SNE를 통해 저차원으로 매핑하면, 데이터들끼리 좀 뭉치는 경향이 있다. 이를 보완하고자 t-SNE를 고안.</p>

<h1 id="t-sne">t-SNE</h1>
<p>t-SNE에서 t는 Student-t를 의미한다. 
기존 SNE보다 가까운 것은 더 가깝게, 먼 것은 더 멀게 표현하여 실제 데이터에 왜곡이 생길지라도 시각적으로 더 예쁘게 그리려고 함. SNE에서 이웃인 정도를 표현하기 위해 고차원과 저차원 공간에서 Gaussian 분포를 이용했다. 하지만 만약 저차원 공간에서 heavy-tailed distribution을 사용한다면? 고차원에서 가까운 점은 저차원에서 더 가까워지고, 고차원에서 먼 점은 저차원에서 더 멀어진다.</p>

<p>t-SNE에서 cost function에 대한 gradient는 기존 SNE에서의 값에 (1+d)^-1 값이 붙는다. 이는 저차원 공간에서 두 점의 거리가 멀어지면 gradient 값이 작아지고, SNE와는 다르게 거리가 어느 이상 멀어지면 서로 밀고 당기는 힘의 크기가 작아진다. 그로 인해 가까운 데이터들은 서로 당기게 되고, 어느 거리가 넘어가면 더 이상 당기는 힘이 증가하지 않고 locally attract하게 된다.</p>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><summary type="html"><![CDATA[SNE Stochastic Neighbor Embedding의 약자. 여기서 임베딩의 의미는 고차원에서 저차원으로 매핑한다는 말이다.]]></summary></entry><entry><title type="html">여러 Boosting 알고리즘 공부하기</title><link href="http://localhost:4000/study/ml-dl/boosting-algorthms/" rel="alternate" type="text/html" title="여러 Boosting 알고리즘 공부하기" /><published>2023-04-22T00:00:00+09:00</published><updated>2023-04-22T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/boosting-algorthms</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/boosting-algorthms/"><![CDATA[<h1 id="adaboost">AdaBoost</h1>
<p>Adaptive Boost의 약자로, 이름에서 알 수 있다시피 적응형이다. 
AdaBoost도 Boosting이므로 classifier를 순차적으로 학습한다. 첫번째 데이터셋에 대해 학습을 진행하고, 그 결과에 따라 다음 데이터셋에 적절한 가중치를 부여하고 다음 모델을 학습한다. 이때 데이터셋에 가중치는 어떻게 부여하는가? 또한 n개의 모델을 학습한 후에 각 모델들에 가중치를 두어 최종 모델을 구해야하는데, 이때도 각 모델에 대한 가중치를 어떻게 정할 것인가? 이 2개의 질문에 대한 답을 하는 것이 목적이다.</p>

<p>전체적인 흐름은 다음과 같다.</p>

<p>m번째 스텝에 대해 데이터 셋에 대한 가중치 \(w_m\)이 주어져 있다고 하자. 그리고 우리의 목적함수는 Exponential Loss의 형태를 가지는데, 그렇게 표현하는 이유는 loss의 축적이 더하기로 되는 것이 아닌 곱하기로 되게끔 하기 위함이다. Loss는 다음과 같이 표현된다.</p>

\[J_m = fcn(\alpha_m, w_m, f_m)\]

<p>먼저, 가중치가 고려된 m번째 데이터 셋에 대해 \(f_m\)을 학습한다. 학습이 완료된 m번째 모델 \(f_m\)을 기존 모델들과 잘 합쳐야하는데, 이는 \(\alpha_m\)을 결정하는 것이다. 이때 목적함수 \(J_m\)을 최소로 하는 \(\alpha_m\) 값을 찾으면 된다. 목적함수를 줄일 때는 gradient를 이용해서 찾는다.</p>

<p>장점:</p>
<ul>
  <li>빠르고 쉽다.</li>
  <li>반복 횟수에 대한 변수를 제외하면 parameter to tune이 없다.</li>
</ul>

<p>단점:</p>
<ul>
  <li>boosting 자체가 데이터 노이즈에 취약한 점이 있다.</li>
  <li>데이터가 부족하면 큰 효과가 없다.</li>
</ul>

<h1 id="gradient-boost">Gradient Boost</h1>

<p>Squared Loss에서 Gradient는 Residual(잔차)를 의미한다.</p>

<h1 id="xgboost">XGBoost</h1>

<p>Extreme Gradient Boost의 약자.</p>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="boosting" /><category term="ensemble" /><summary type="html"><![CDATA[AdaBoost Adaptive Boost의 약자로, 이름에서 알 수 있다시피 적응형이다. AdaBoost도 Boosting이므로 classifier를 순차적으로 학습한다. 첫번째 데이터셋에 대해 학습을 진행하고, 그 결과에 따라 다음 데이터셋에 적절한 가중치를 부여하고 다음 모델을 학습한다. 이때 데이터셋에 가중치는 어떻게 부여하는가? 또한 n개의 모델을 학습한 후에 각 모델들에 가중치를 두어 최종 모델을 구해야하는데, 이때도 각 모델에 대한 가중치를 어떻게 정할 것인가? 이 2개의 질문에 대한 답을 하는 것이 목적이다.]]></summary></entry><entry><title type="html">Ensemble Method 공부하기</title><link href="http://localhost:4000/study/ml-dl/ensemble-method/" rel="alternate" type="text/html" title="Ensemble Method 공부하기" /><published>2023-04-22T00:00:00+09:00</published><updated>2023-04-22T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/ensemble-method</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/ensemble-method/"><![CDATA[<h1 id="preliminary-knowledge">Preliminary Knowledge</h1>
<h2 id="bootstrap-요약">Bootstrap 요약</h2>
<p>Bootstrap (부트스트랩)은 데이터 내에서 반복적으로 샘플을 사용하는 resampling 방법 중 하나.</p>

<p>Bootstrap sampling을 하면 애초에 한 개 밖에 없었던 우리들의 sample data set을 n개의 sample data set을 가지고 있는 것과 같은 효과를 누릴 수 있게 한다. 이를 통해 우리는 data의 variance를 상당히 잘 근사 할 수 있는 결과를 볼 수 있다.</p>

<p>전체 크기가 n개인 원래의 데이터셋 S가 있다고 하자. S를 통해 크기가 N개인, 기존보다 더 큰 데이터셋 S’을 얻고 싶을 때, 부트스트랩 샘플링을 할 수 있다. 원래 데이터셋 S에서 복원 추출을 통해 m개를 뽑는다. 그렇게 뽑은 하나의 데이터셋을 \(s_i\)라고 하자. 이러한 복원추출을 N번 반복한다. 그러면 \(S'=\{s_1, \cdots, s_N \}\)의 새로운 데이터 셋을 구할 수 있다.</p>

<p>부트스트랩을 통해 얻어진 새로운 데이터 셋은 기존의 데이터 셋과 비슷한 분포를 가진다.</p>

<h1 id="ensemble-model">Ensemble Model</h1>

<p>강력한 하나의 모델 대신, 여러 개의 간단한 모델을 만들고 그들을 조합하여 예측하는 것.
예를 들어 Classifier를 만든다고 생각할 때, 엄청 복잡한 하나의 모델을 만들기보다는 간단한 classifer들을 만들고, 결과를 내야할 때 각 classifer에게 물어보고, 그것들의 대답 비율을 따져 최종 결정을 내리는 것.</p>

<p>대표적인 앙상블 유형에는 다음이 있다: Voting, Bagging, Boosting.</p>

<h2 id="bagging">Bagging</h2>

<p>Bootstrap Aggregation의 약자로, 샘플을 여러 번 뽑아(Bootstrap) 각 모델을 학습시켜 결과물을 집계(Aggregration)하는 방법이다. 원래 데이터 셋에서 작은 여러 개의 데이터 셋을 샘플링한다(bootstrap). 각 데이터 셋으로 모델을 학습시킨다. 그리고 학습된 모델의 결과를 집계하여 최종 결과 값을 구한다(Aggregation).</p>

<p>Categorical data는 각 모델들이 말한 catogory의 빈도수를 확인하고, 가장 많이 나온 결과를 채택하면 된다. Regression과 같이 continuous data를 다루는 경우, 각 모델들의 결과를 평균낼 수 있다.</p>

<h2 id="voting">Voting</h2>

<p>Voting은 Bagging과 비슷하게, 부트스트랩을 통해 구해진 여러 데이터 셋을 이용한다. 하지만 Bagging은 각 데이터 셋에 같은 알고리즘의 모델을 사용한다면, Voting은 각 데이터 셋에 대해 다른 알고리즘의 모델들을 사용하고, 각 모델이 자신만의 알고리즘으로 답한 결과를 이용하여 최종 결과를 도출한다. 예를 들어 분류 문제에서 Voting은 각 데이터 셋에 대해 KNN, SVM, Linear Regression 등의 알고리즘을 사용할 수 있다.</p>

<h2 id="boosting">Boosting</h2>

<p>Bagging에서는 부트스트랩을 통해 얻어진 데이터 셋에 대해 각각의 모델들이 “독립적으로” 학습하게 된다. 하지만 Boosting에서는 이전 모델의 학습이 다음 모델의 학습에 영향을 미친다. 이전 모델의 학습 결과에 대해 오답 데이터에는 더 큰 가중치를 두어, 새로운 모델은 이전에 모델이 틀린 부분에 대해 조금 더 집중해서 학습하게 된다. Bagging은 병렬적인 과정이라면, Boosting은 순차적인 과정이다.</p>

<h1 id="characteristics-of-ensemble-model">Characteristics of Ensemble Model</h1>

<ul>
  <li>Bias를 줄인다. 쉬운 모델들을 중첩하여 하나의 모델을 만들기 때문에 dicision boundary가 부드럽게 형성된다. 그렇게 모델의 복잡도를 늘리기 때문에 모델의 bias가 작아진다.</li>
  <li></li>
</ul>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="boost" /><category term="learning" /><summary type="html"><![CDATA[Preliminary Knowledge Bootstrap 요약 Bootstrap (부트스트랩)은 데이터 내에서 반복적으로 샘플을 사용하는 resampling 방법 중 하나.]]></summary></entry><entry><title type="html">Kernel method 공부하기</title><link href="http://localhost:4000/study/ml-dl/kernel-method/" rel="alternate" type="text/html" title="Kernel method 공부하기" /><published>2023-04-20T00:00:00+09:00</published><updated>2023-04-20T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/kernel-method</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/kernel-method/"><![CDATA[<h1 id="linear-regression-with-non-linear-features">Linear Regression with Non-linear Features</h1>

<p>어떤 데이터 x를 다루고 싶을 때, 그 x를 그대로 모델의 입력값으로 사용할 수도 있지만, 어떤 \(y=f(x)\)라는 매핑을 통해 일차적으로 변환을 하고, 그 이후에 모델에 집어넣을 수 있다. 예를 들어 x를 n차 다항식 형태로 매핑을 한다고 생각해보자.</p>

\[y = w_0x_0 + \cdots w_nx_n = [w_0, \cdots, w_n]^T \cdot [x^0, \cdots, x^n] = \mathbf{w \cdots x}\]

<p>linear regression에서 선형성은 파라미터 \(w\)에 대한 선형성이다. \(x\)는 다항함수를 지나기 때문에 선형성이 유지되진 않지만, 모델은 \(w_i\)에 대해 1차로 구성되어 있기 때문에 파라미터에 대한 선형성을 가지고 있다. 이때 어떤 변환을 거쳐야 하는지는 데이터의 특성과 밀접한 관련이 있다.</p>
<ul>
  <li>주기적인 데이터를 가진 경우는 \(sin / cos\) 등과 같은 harmonic function 등을 사용할 수 있다.</li>
  <li>고차항이 필요하다면 다음의 변환을 생각해볼 수 있다.</li>
</ul>

\[\phi(x) = [1, x, x^2, \cdots ]\]

<ul>
  <li>변수 사이의 상관 관계가 있다면 다음 변환</li>
</ul>

\[\phi(x) = [1, x_{1}x_{2}, x_{3}x_{4}, \cdots]\]

<p>이 방법에서 핵심은 non-linear feature + linear model이라는 것. 즉 변수는 비선형 변환을 통해 복잡한 패턴을 잡아낼 수 있지만 모델 자체는 선형이기 때문에 다루기 쉽다. 위에 예시에서 보듯 보통 feature를 생성할 때는 원래 데이터보다 더 고차원의 공간으로 매핑을 하게 된다. 이는 데이터를 다룰 때 계산량을 키우게 되는 단점을 가지고 있다. 이를 보안하기 위해 <strong>kernel method</strong>를 생각하게 되었다.</p>

<h1 id="kernel">Kernel</h1>

<h2 id="kernel-method">kernel method</h2>

<p>위 예시에서 나타난 공통점인데, input x는 feature로의 변환을 거치고, 그 변환된 feature들은 모델의 파라미터와 dot product를 하게 된다. kernel method는 중간 단계인 x-&gt;y로의 feature 변환을 건너 뛰려는 목적을 가지고 있다. 이를 <strong>kernel trick</strong>이라고 부른다. 이 커널 트릭을 통해 고차원으로의 변환을 찾거나 계산할 필요 없이, 바로 저차원의 데이터를 가지고 계산하면 된다. 쉽게 말해서 고차원의 데이터가 등장하는 중간 단계를 건너 뛰고 똑같은 계산 결과를 얻는 과정이다.</p>

<p>다음의 예시를 보자. 2차원 데이터 x,y에 대해 2nd order polynomial kernel \(k(x,y)=(x \cdot y)^2\)를 생각해보자. 커널 계산 결과는 다음과 같다. 우리는 2차원 데이터 x,y 만을 가지고 계산했지만 사실 그 과정에는 3차원으로의 매핑 -&gt; 내적 이라는 계산 과정이 들어간 것이다.</p>

\[k(x,y)=(x \cdot y)^2=(x_1 y_1 + x_2 y_2)^2 = (x_1^2, x_2^2, \sqrt{2} x_1 x_2) \cdot (y_1^2, y_2^2, \sqrt{2} y_1 y_2)\]

<h2 id="kernel-examples">kernel examples</h2>
<ul>
  <li>Linear Kernel: \(k(x,y) = x \cdot y\)</li>
  <li>Polynomial kernel: \(k(x,y) = (x \cdot y)^d or (x \cdot y + 1)^d\)</li>
  <li>Gaussian of RBF kernel: \(k(x,y) = \exp{(\frac{\vert x-y \vert}{2l^2})}\)</li>
</ul>

<h2 id="kernel-properties">kernel properties</h2>
<p>커널을 통해 feature transformation 계산을 하지 않아도 되는 것은 알겠는데, 그렇다면 특성으로의 변환과 커널 함수는 서로 일대일 대응이 되는지 궁금해진다. 즉 임의의 feature로의 변환을 생각했을 때 그에 대응되는 커널 함수 k가 있는지, 그리고 임의의 커널함수 k를 생각했을 때 그에 대응되는 feature가 있는지 말이다.</p>

<p>커널이 다음의 두 조건을 만족하면, 그에 대응되는 유일한 feature가 존재한다고 한다. 근데 실제로는 PSD가 아닌 커널 함수여도 충분히 유용한 커널 함수가 존재한다더라.</p>
<ul>
  <li>symmetric</li>
  <li>positive semi-definite (PSD)</li>
</ul>

<p>kernel은 다음과 같이 normalized 될 수 있다.</p>

<h1 id="algorithms-using-kernel">Algorithms Using Kernel</h1>
<p>선형 모델을 생각해보면 \(\mathbf{w^T x}\) 항이 등장한다. 이는 weight vector가 data와 같은 공간에 위치하는 것을 의미한다(중요).</p>

<h2 id="kernel-perceptron-algorithm">Kernel Perceptron Algorithm</h2>
<p>perceptron은 x를 인풋으로 받아 그 값을 +1/-1로 구분하는 단순한 모델. 
이것을 풀다보면 \(\mathbf{x \cdot x}\) 가 등장하는데, 이 항을 커널 함수로 바꾸는 알고리즘.
여기서 학습은 계수값인 \(\alpha\)를 업데이트 하는 것.</p>

<h2 id="kernel-linear-regression">Kernel Linear Regression</h2>
<p>Regression model에서 Ordinary Least Square(OLS)는 오차의 제곱을 최소로 하도록 하는 것.</p>

<p>Kernelization</p>

<p>우리가 찾고자 하는 solution of weight vector를 데이터 포인트의 linear combination으로 표현해보자.</p>

<p>\(\mathbf{w}=\sum_{i=1}{n}\alpha_i\mathbf{x_i}=\mathbf{X}\vec{\alpha}\)
\(\mathbf{w}=\mathbf{(XX^T)^{-1}Xy}\)</p>

<p>당연히 아직은 alpha값은 모르며, 학습을 통해 alpha를 업데이트 해갈 것이다. 가중치를 찾는 것은 alpha를 찾는 것과 동일. 위처럼 표현한 가중치 벡터에 데이터를 곱하면 아래와 같다.</p>

\[\mathbf{w^T z}=\sum_{i=1}{n}\alpha_i\mathbf{x_i^T z}\]

<p>위 식에서 \(\mathbf{x^T z}=k(\mathbf{x}, \mathbf{z})\)로 kernelize 할 수 있다. 그렇게 되면 아래 같이 정리된다.</p>

\[\vec{\alpha} = \mathbf{K^{-1}y}\]

<p>Ridge regression은 위와 유사한다.</p>

<p>*유사도라는 개념. w를 x의 선형 결합으로 표현한다는 것은 데이터 사이의 유사도 개념과 밀접하다. perceptron 예시 참고.</p>

<h2 id="kernel-pca">Kernel PCA</h2>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="kernel" /><summary type="html"><![CDATA[Linear Regression with Non-linear Features]]></summary></entry><entry><title type="html">EM 알고리즘 공부하기</title><link href="http://localhost:4000/study/ml-dl/expectation-maximization/" rel="alternate" type="text/html" title="EM 알고리즘 공부하기" /><published>2023-04-18T00:00:00+09:00</published><updated>2023-04-18T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/expectation-maximization</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/expectation-maximization/"><![CDATA[]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="EM" /><category term="GMM" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Undirected model 공부하기</title><link href="http://localhost:4000/study/ml-dl/undirected-graphical-model/" rel="alternate" type="text/html" title="Undirected model 공부하기" /><published>2023-04-18T00:00:00+09:00</published><updated>2023-04-18T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/undirected-graphical-model</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/undirected-graphical-model/"><![CDATA[<h1 id="directed-vs-undirected">Directed vs Undirected</h1>
<ul>
  <li>적용하고자 하는 application에서 변수 간 order가 있을 수도 있고 없을 수도 있음.</li>
  <li>오늘의 날씨와 내일의 날씨는 order가 있음.</li>
  <li>이미지의 픽셀 정보는 order가 없음.</li>
  <li>순서가 있는 경우에는 DAG 모델을 주로 사용하고, 순서가 없는 경우에는 Undirected Graphical Model(UG, UGM) 혹은 Markov Random Fields(MRF)를 사용한다.</li>
  <li>BN에서는 Conditional Probability Table(CPT)를 사용하여 변수 간 관계를 정했다면, UG에서는 각 변수 노드간 연결이 “얼마나 잘 어울리는가”, “그럴듯한 조합이다”의 정도를 판단한다. (?)</li>
</ul>

<h2 id="ug의-예시">UG의 예시</h2>
<ol>
  <li>Ising Model
    <ul>
      <li>격자 구조를 갖는 분자 구조에서 각 분자의 극성(+/-)은 해당 분자의 주변 분자에서 영향을 갖는다.</li>
      <li>확률이 높은 상태라는 것은 에너지가 낮은 상태라는 것.</li>
    </ul>
  </li>
  <li>이미지 처리
    <ul>
      <li>이미지에서 denoising. noised pixel value는 실제 관측된 값, true pixel value는 관측되지 않은 값이라 생각할 수 있다. noised value를 가지고 denoised value를 확률적으로 추정할 수 있을까?</li>
    </ul>
  </li>
</ol>

<h1 id="ug의-수학적-표현">UG의 수학적 표현</h1>

<h2 id="정의">정의</h2>
<ul>
  <li><strong>Clique</strong>
    <ul>
      <li>어떤 그래프 \(G\)가 주어져 있을 때, 그것의 subgraph 중 complete graph를 의미한다.</li>
      <li>즉 부분 그래프 중 완전그래프를 clique라고 정의.</li>
      <li>노드의 개수가 0개인 경우 또한 clique</li>
      <li>노드의 개수가 1개인 경우 또한 clique</li>
      <li>Maximal Clique: 모든 clique 중에 가장 큰 clique. 가장 크다는 것은 어떤 노드를 추가하더라도 clique이 되지 못하는 경우를 의미.</li>
    </ul>
  </li>
  <li><strong>Potential Function</strong>, \(\psi_c(\mathbf{x}_c)\)
    <ul>
      <li>\(c\)라는 clique 안의 x에 대해 \(\mathbf{x}_c\)가 얼마나 그럴듯한지 (확률이 높은지) 의미하는 함수.</li>
    </ul>
  </li>
  <li><strong>Partition Function</strong>, Z
    <ul>
      <li>Normalize를 위한 상수.</li>
      <li>\(Z = \sum_{x_1, \cdots, x_n} \prod_{c\in C} \psi_c(x_c)\): 모든 clique에 대한 potential function 값을 모두 곱한 뒤, 가능한 모든 x의 경우에 대해 더한다.</li>
    </ul>
  </li>
</ul>

<h2 id="표현">표현</h2>
<ul>
  <li>n개의 노드를 가진 undirected graph, \(H\)를 생각하자. n개 변수들의 확률 분포는 \(P(X_1, \cdots, X_n)\)으로 표현할 수 있다.</li>
  <li>확률 분포는 아래와 같이 potential functions의 곱으로 표현됨. (이처럼 될 수 있다는 정리는 뒷부분에)</li>
  <li>
\[P(x_1, \cdots, x_n) = \frac{1}{Z} \prod_{c\in C}\psi_c(x_c)\]
  </li>
  <li>clique을 이용하여 UG의 확률분포를 표현할 수 있는데, maximal clique만 사용할 수도 있고, 모든 clique을 다 사용할 수도 있다.
    <ul>
      <li>
\[P(x_1, x_2, x_3, x_4) = 
\frac{1}{Z} \psi_{124}(\mathbf{x}_{124}) \psi_{234}(\mathbf{x}_{234})\]
      </li>
      <li>만약 3개 clique만을 사용한다면 변수 2개 사이 관계는 못 보지 않을까?</li>
      <li>즉 확률 분포를 어떤 clique들의 조합으로 보는지 또한 모델링 과정 중 하나일 듯.</li>
    </ul>
  </li>
</ul>

<h2 id="interpretation-of-clique-potentials">Interpretation of clique potentials</h2>
<p>X-Y-Z 라는 모델은 X와 Z의 Y에 대한 조건부 확률을 의미한다: \(X \mathrel{\unicode{x2AEB}} Z \vert Y\) (일단 지금 단계에서는 받아들이자.) 확률 분포는 아래와 같이 주어져야 한다.</p>

\[p(x,y,z) = p(y) p(x \vert y) p(z \vert y)\]

<p>또한 위에서 살펴본 것처럼, 확률 분포는 potential functions의 곱으로 표현된다.</p>

\[p(x,y,z) = \psi_{xy} \psi_{yz}\]

<p>그렇다면 여기서 potential function의 의미는?</p>
<ul>
  <li>\(p(x,y,z) = p(x,y) p(z \vert y)\) 혹은 \(p(x,y,z) = p(z,y) p(x \vert y)\)로도 표현할 수 있지만, 그렇게 되면 각각의 potential은 marginalize 혹은 conditionalize 될 수 없다. (?)</li>
  <li>따라서 potential function을 확률로서 생각하지 말고, 그 값이 높으면 확률이 높으므로 서로 연결된 값이 얼마나 그럴듯한 값들을 가지고 있는지 정도로 생각하자.</li>
</ul>

<h2 id="clique-potentials-in-exponential-form">Clique Potentials in Exponential Form</h2>
<p>clique potential이 항상 양수가 되게끔 하는 것이 불편한 경우가 있다. 예를 들어 분자의 극성을 표현할 때는 +/-로 표현하는 것이 편하겠지. 그렇기 때문에 실수 범위에서 정의되는 함수를 하나 생각하고 그 함수에 expotential 함수를 취해 양수 범위로 mapping하자.</p>

\[\psi_c(x_c) = \exp\{ -\phi_c(x_c) \}\]

<p>그렇게 되면 확률 분포는 Gibbs distribution을 따르게 된다.</p>

\[p(x) = 
\frac{1}{Z} \prod_{c\in C} \psi_c(x_c) = 
\frac{1}{Z} \exp\left( -\sum_{c\in C} \phi_c(x_c) \right)\]

<h1 id="왜-clique를-이용하여-확률-분포를-생각하는가">왜 clique를 이용하여 확률 분포를 생각하는가?</h1>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="graph model" /><category term="bayesian network" /><category term="UG" /><category term="DAG" /><summary type="html"><![CDATA[Directed vs Undirected 적용하고자 하는 application에서 변수 간 order가 있을 수도 있고 없을 수도 있음. 오늘의 날씨와 내일의 날씨는 order가 있음. 이미지의 픽셀 정보는 order가 없음. 순서가 있는 경우에는 DAG 모델을 주로 사용하고, 순서가 없는 경우에는 Undirected Graphical Model(UG, UGM) 혹은 Markov Random Fields(MRF)를 사용한다. BN에서는 Conditional Probability Table(CPT)를 사용하여 변수 간 관계를 정했다면, UG에서는 각 변수 노드간 연결이 “얼마나 잘 어울리는가”, “그럴듯한 조합이다”의 정도를 판단한다. (?)]]></summary></entry><entry><title type="html">cluster test</title><link href="http://localhost:4000/linux/cluster/cluster-test/" rel="alternate" type="text/html" title="cluster test" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/linux/cluster/cluster-test</id><content type="html" xml:base="http://localhost:4000/linux/cluster/cluster-test/"><![CDATA[<h1 id="problem">problem</h1>
<ul>
  <li>ANSYS client host에서 server host로 license status 요청하기</li>
</ul>

<h1 id="solution">Solution</h1>
<ul>
  <li><code class="language-plaintext highlighter-rouge">lmutil lmstat -c PORT@SERVER -a</code></li>
  <li>
    <p>모든 프로그램에 대한 현재 라이센스 상태를 보여준다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>root@master ~]<span class="nv">$ </span>/nopt/ansys_inc/v202/licensingclient/linx64/lmutil lmstat <span class="nt">-c</span> 1055@license.tml <span class="nt">-a</span>

lmutil - Copyright <span class="o">(</span>c<span class="o">)</span> 1989-2015 Flexera Software LLC. All Rights Reserved.
Flexible License Manager status on Sun 4/16/2023 14:03

License server status: 1055@license.tml
    License file<span class="o">(</span>s<span class="o">)</span> on license.tml: /ansys_inc/shared_files/licensing/license_files/ansyslmd.lic:

license.tml: license server UP <span class="o">(</span>MASTER<span class="o">)</span> v11.19.0

Vendor daemon status <span class="o">(</span>on license.tml<span class="o">)</span>:

ansyslmd: UP v11.19.0
Feature usage info:

Users of anshpc:  <span class="o">(</span>Total of 1080 licenses issued<span class="p">;</span>  Total of 124 licenses <span class="k">in </span>use<span class="o">)</span>

<span class="s2">"anshpc"</span> v2020.0514, vendor: ansyslmd, expiry: 1-jan-0
floating license

    shlee t009 t009.tml 60048 <span class="o">(</span>v2020.0507<span class="o">)</span> <span class="o">(</span>license.tml/1055 1404<span class="o">)</span>, start Sun 4/16 14:02, 124 licenses

Users of 1spacdes:  <span class="o">(</span>Total of 26 licenses issued<span class="p">;</span>  Total of 0 licenses <span class="k">in </span>use<span class="o">)</span>

Users of cfd_base:  <span class="o">(</span>Total of 25 licenses issued<span class="p">;</span>  Total of 1 license <span class="k">in </span>use<span class="o">)</span>

<span class="s2">"cfd_base"</span> v2020.0514, vendor: ansyslmd, expiry: 1-jan-0
floating license

    shlee t009 t009.tml 60048 <span class="o">(</span>v2020.0507<span class="o">)</span> <span class="o">(</span>license.tml/1055 1304<span class="o">)</span>, start Sun 4/16 14:02

...
</code></pre></div>    </div>
  </li>
  <li>현재 사용중인 license만 출력하기 위해 별도의 shell script 작성</li>
  <li>사용중인 라이센스에 대해 USER, HOST, Start Time, (USED, AVAILABLE, TOTAL) 출력</li>
  <li>HPC의 경우, 해당 작업이 사용중인 license 개수도 출력
    <ol>
      <li><code class="language-plaintext highlighter-rouge">lmutil lmstat -c PORT@SERVER -a</code>: 전체 license status를 출력한다.</li>
      <li><code class="language-plaintext highlighter-rouge">sed '/Total of 0 licenses in use/d'</code>: 사용중인 license 개수가 0인 프로그램 문장은 지운다.</li>
      <li><code class="language-plaintext highlighter-rouge">sed '/^[[:space:]]*$/d'</code>: 빈 문장 지운다.</li>
      <li><code class="language-plaintext highlighter-rouge">awk '!/floating/' | awk '!/expiry/' </code>: license 사용중인 프로그램의 경우 ‘floating’과 ‘expiry’란 단어가 들어간 문장이 등장하는데 필요 없으므로 지운다.</li>
      <li><code class="language-plaintext highlighter-rouge">sed -e '1,8d'</code>: 앞에 필요없는 문장 지운다.</li>
      <li><code class="language-plaintext highlighter-rouge">$INDEX, $PROGRAMS</code>: For loop을 돌릴 때 필요한 변수. For loop을 돌면서 사용중인 프로그램에 대해서 각각 USER, Host 등 필요한 정보를 양식에 맞춰 기록한다.</li>
      <li><code class="language-plaintext highlighter-rouge">USER</code>, <code class="language-plaintext highlighter-rouge">HOST</code>, <code class="language-plaintext highlighter-rouge">DATE</code> 등 필요한 정보를 <code class="language-plaintext highlighter-rouge">awk</code>, <code class="language-plaintext highlighter-rouge">sed</code>, <code class="language-plaintext highlighter-rouge">printf</code> 등의 command를 통해 양식에 맞도록 출력한다.</li>
      <li>임시 파일을 지우면서 마무리한다.</li>
    </ol>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>root@master bin]# <span class="nb">cat </span>query_license_ansys.sh 
<span class="c">#!/bin/bash</span>
<span class="nb">echo</span> <span class="s2">""</span>
<span class="nb">echo</span> <span class="s2">"Only licenses being used now are shown."</span>
<span class="nb">echo</span> <span class="s2">""</span>

<span class="nv">FILE</span><span class="o">=</span><span class="nv">$HOME</span>/.license_status_ansys.tmp

/nopt/ansys_inc/v202/licensingclient/linx64/lmutil lmstat <span class="nt">-c</span> 1055@license.tml <span class="nt">-a</span> |<span class="se">\</span>
<span class="nb">sed</span> <span class="s1">'/Total of 0 licenses in use/d'</span> |<span class="se">\</span>
<span class="nb">sed</span> <span class="s1">'/^[[:space:]]*$/d'</span> |<span class="se">\</span>
<span class="nb">awk</span> <span class="s1">'!/floating/'</span> | <span class="nb">awk</span> <span class="s1">'!/expiry/'</span> |<span class="se">\</span>
<span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'1,8d'</span> <span class="o">&gt;</span> <span class="nv">$FILE</span>

<span class="nv">INDEX</span><span class="o">=(</span><span class="si">$(</span><span class="nb">cat</span> <span class="nv">$FILE</span> | <span class="nb">nl</span> | <span class="nb">grep</span> <span class="s2">"Users of"</span> | <span class="nb">awk</span> <span class="s1">'{print $1}'</span><span class="si">)</span> <span class="k">$((</span> <span class="sb">`</span><span class="o">(</span><span class="nb">cat</span> <span class="nv">$FILE</span> | <span class="nb">nl</span> | <span class="nb">tail</span> <span class="nt">-1</span> | <span class="nb">awk</span> <span class="s1">'{print $1}'</span><span class="o">)</span><span class="sb">`</span> <span class="o">+</span> <span class="m">1</span> <span class="k">))</span> <span class="o">)</span>
<span class="nv">PROGRAMS</span><span class="o">=(</span><span class="si">$(</span><span class="nb">cat</span> <span class="nv">$FILE</span> | <span class="nb">grep</span> <span class="s2">"Users of"</span> | <span class="nb">awk</span> <span class="s1">'{print $3}'</span> | <span class="nb">sed</span> <span class="s1">'s/://g'</span><span class="si">)</span><span class="o">)</span>

<span class="k">for </span>idx <span class="k">in</span> <span class="sb">`</span><span class="nb">seq </span>0 <span class="k">$((</span> <span class="k">${#</span><span class="nv">PROGRAMS</span><span class="p">[@]</span><span class="k">}</span> <span class="o">-</span><span class="m">1</span> <span class="k">))</span><span class="sb">`</span>
<span class="k">do
    </span><span class="nv">i</span><span class="o">=</span><span class="k">${</span><span class="nv">INDEX</span><span class="p">[</span><span class="nv">$idx</span><span class="p">]</span><span class="k">}</span>
    <span class="nv">j</span><span class="o">=</span><span class="k">${</span><span class="nv">INDEX</span><span class="p">[</span><span class="k">$((</span> <span class="nv">$idx</span> <span class="o">+</span> <span class="m">1</span> <span class="k">))</span><span class="p">]</span><span class="k">}</span>
    <span class="nv">PROGRAM</span><span class="o">=</span><span class="k">${</span><span class="nv">PROGRAMS</span><span class="p">[</span><span class="nv">$idx</span><span class="p">]</span><span class="k">}</span>
    <span class="nv">TOT</span><span class="o">=</span><span class="si">$(</span><span class="nb">head</span> -<span class="nv">$i</span> <span class="nv">$FILE</span> | <span class="nb">tail</span> <span class="nt">-n</span> +<span class="nv">$i</span> | <span class="nb">awk</span> <span class="s1">'{print $6}'</span><span class="si">)</span>
    <span class="nv">USE</span><span class="o">=</span><span class="si">$(</span><span class="nb">head</span> -<span class="nv">$i</span> <span class="nv">$FILE</span> | <span class="nb">tail</span> <span class="nt">-n</span> +<span class="nv">$i</span> | <span class="nb">awk</span> <span class="s1">'{print $11}'</span><span class="si">)</span>
    <span class="nv">AVA</span><span class="o">=</span><span class="k">$((</span> <span class="nv">$TOT</span> <span class="o">-</span> <span class="nv">$USE</span> <span class="k">))</span>
    <span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"license in used: </span><span class="k">${</span><span class="nv">PROGRAM</span><span class="k">}</span><span class="s2"> (used, available, total) = (</span><span class="k">${</span><span class="nv">USE</span><span class="k">}</span><span class="s2">, </span><span class="k">${</span><span class="nv">AVA</span><span class="k">}</span><span class="s2">, </span><span class="k">${</span><span class="nv">TOT</span><span class="k">}</span><span class="s2">)"</span>

    <span class="k">if</span> <span class="o">[[</span> <span class="nv">$PROGRAM</span> <span class="o">==</span> <span class="s2">"anshpc"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
        </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">" --------------------------------------------- "</span>
        <span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"|    User    |    Host    |  Start Time | Use |"</span>	
        <span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"|---------------------------------------------|"</span>
    <span class="k">else
        </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">" --------------------------------------- "</span>
        <span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"|    User    |    Host    |  Start Time |"</span>	
        <span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"|---------------------------------------|"</span>
    <span class="k">fi

    for </span>k <span class="k">in</span> <span class="sb">`</span><span class="nb">seq</span> <span class="k">$((</span> <span class="nv">$i</span> <span class="o">+</span> <span class="m">1</span> <span class="k">))</span> <span class="k">$((</span> <span class="nv">$j</span> <span class="o">-</span> <span class="m">1</span> <span class="k">))</span><span class="sb">`</span>
    <span class="k">do
        </span><span class="nv">LINE</span><span class="o">=</span><span class="si">$(</span><span class="nb">head</span> -<span class="nv">$k</span> <span class="nv">$FILE</span> | <span class="nb">tail</span> <span class="nt">-n</span> +<span class="nv">$k</span><span class="si">)</span>
			
        <span class="nv">USER</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$LINE</span> | <span class="nb">awk</span> <span class="s1">'{print $1}'</span> | <span class="nb">sed</span> <span class="s1">'s/$/         /'</span> | <span class="nb">cut</span> <span class="nt">-c</span> <span class="nt">-10</span><span class="si">)</span>
        <span class="nv">COMP</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$LINE</span> | <span class="nb">awk</span> <span class="s1">'{print $2}'</span> | <span class="nb">sed</span> <span class="s1">'s/$/         /'</span> | <span class="nb">cut</span> <span class="nt">-c</span> <span class="nt">-10</span><span class="si">)</span>
        <span class="nv">DATE</span><span class="o">=</span><span class="si">$(</span><span class="nb">printf</span> <span class="s2">"%02d/%02d"</span> <span class="si">$(</span><span class="nb">echo</span> <span class="nv">$LINE</span> | <span class="nb">awk</span> <span class="s1">'{print $10}'</span> | <span class="nb">sed</span> <span class="s1">'s/\// /'</span><span class="si">))</span>
        <span class="nv">TIME</span><span class="o">=</span><span class="si">$(</span><span class="nb">printf</span> <span class="s2">"%02d:%s"</span>  <span class="si">$(</span><span class="nb">echo</span> <span class="nv">$LINE</span> | <span class="nb">awk</span> <span class="s1">'{print $11}'</span> | <span class="nb">sed</span> <span class="s1">'s/:/ /'</span> | <span class="nb">sed</span> <span class="s1">'s/,//'</span> <span class="si">))</span>
			
        <span class="k">if</span> <span class="o">[[</span> <span class="nv">$PROGRAM</span> <span class="o">==</span> <span class="s2">"anshpc"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
            </span><span class="nv">USEHPC</span><span class="o">=</span><span class="si">$(</span><span class="nb">printf</span> <span class="s2">"%3d"</span> <span class="si">$(</span><span class="nb">echo</span> <span class="nv">$LINE</span> | <span class="nb">awk</span> <span class="s1">'{print $12}'</span> <span class="si">))</span>
            <span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"| </span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2"> | </span><span class="k">${</span><span class="nv">COMP</span><span class="k">}</span><span class="s2"> | </span><span class="k">${</span><span class="nv">DATE</span><span class="k">}</span><span class="s2">-</span><span class="k">${</span><span class="nv">TIME</span><span class="k">}</span><span class="s2"> | </span><span class="k">${</span><span class="nv">USEHPC</span><span class="k">}</span><span class="s2"> |"</span>
        <span class="k">else
            </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"| </span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2"> | </span><span class="k">${</span><span class="nv">COMP</span><span class="k">}</span><span class="s2"> | </span><span class="k">${</span><span class="nv">DATE</span><span class="k">}</span><span class="s2">-</span><span class="k">${</span><span class="nv">TIME</span><span class="k">}</span><span class="s2"> |"</span>
        <span class="k">fi
    done

		
    if</span> <span class="o">[[</span> <span class="nv">$PROGRAM</span> <span class="o">==</span> <span class="s2">"anshpc"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
        </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">" --------------------------------------------- "</span>
    <span class="k">else
        </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">" --------------------------------------- "</span>
    <span class="k">fi
    </span><span class="nb">echo</span> <span class="s2">""</span>
<span class="k">done

</span><span class="nb">rm</span> <span class="nv">$FILE</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>위 script를 사용한 출력 결과는 아래와 같다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>root@master ~]<span class="nv">$ </span>query_license_ansys 

Only licenses being used now are shown.

license <span class="k">in </span>used: anshpc <span class="o">(</span>used, available, total<span class="o">)</span> <span class="o">=</span> <span class="o">(</span>124, 956, 1080<span class="o">)</span>
<span class="nt">---------------------------------------------</span> 
|    User    |    Host    |  Start Time | Use |
|---------------------------------------------|
| shlee      | t009       | 04/16-14:03 | 124 |
<span class="nt">---------------------------------------------</span> 

license <span class="k">in </span>used: cfd_base <span class="o">(</span>used, available, total<span class="o">)</span> <span class="o">=</span> <span class="o">(</span>1, 24, 25<span class="o">)</span>
<span class="nt">---------------------------------------</span> 
|    User    |    Host    |  Start Time |
|---------------------------------------|
| shlee      | t009       | 04/16-14:03 |
<span class="nt">---------------------------------------</span> 

license <span class="k">in </span>used: cfd_solve_level1 <span class="o">(</span>used, available, total<span class="o">)</span> <span class="o">=</span> <span class="o">(</span>1, 24, 25<span class="o">)</span>
<span class="nt">---------------------------------------</span> 
|    User    |    Host    |  Start Time |
|---------------------------------------|
| shlee      | t009       | 04/16-14:03 |
<span class="nt">---------------------------------------</span> 

license <span class="k">in </span>used: cfd_solve_level2 <span class="o">(</span>used, available, total<span class="o">)</span> <span class="o">=</span> <span class="o">(</span>1, 24, 25<span class="o">)</span>
<span class="nt">---------------------------------------</span> 
|    User    |    Host    |  Start Time |
|---------------------------------------|
| shlee      | t009       | 04/16-14:03 |
<span class="nt">---------------------------------------</span> 

</code></pre></div>    </div>
  </li>
</ul>

<h1 id="command">Command</h1>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">awk</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sed</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">For</code></p>
  </li>
</ol>]]></content><author><name>bear11235</name></author><category term="linux" /><category term="cluster" /><summary type="html"><![CDATA[problem ANSYS client host에서 server host로 license status 요청하기]]></summary></entry></feed>