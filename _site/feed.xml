<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-05-13T12:34:30+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">bear11235’s blog</title><subtitle>bear11235&apos;s study blog. </subtitle><author><name>bear11235</name></author><entry><title type="html">Coherent Structures in Turbulence</title><link href="http://localhost:4000/study/turbulence/coherent-structures/" rel="alternate" type="text/html" title="Coherent Structures in Turbulence" /><published>2023-05-12T00:00:00+09:00</published><updated>2023-05-12T00:00:00+09:00</updated><id>http://localhost:4000/study/turbulence/coherent-structures</id><content type="html" xml:base="http://localhost:4000/study/turbulence/coherent-structures/"><![CDATA[<h1 id="coherent-structures-and-turbulence-1968">Coherent structures and turbulence (1968)</h1>
<ul>
  <li>Journal of Fluid Mechanics (1986)</li>
  <li>Author: FAZLE HUSSAIN</li>
</ul>

<h2 id="introduction">Introduction</h2>
<p>Coherent structure(난류 구조)는 무질서하게 보이는 난류에서 질서를 찾고자 하는 우리의 노력이 투영된 결과로 볼 수 있다.</p>

<h2 id="the-nature-of-coherent-structures">The nature of coherent structures</h2>
<h3 id="earlier-approaches---flow-visualization">Earlier approaches - flow visualization</h3>
<p>거의 대부분의 난류 구조 연구는 유동 가시화에 기반하여 진행되었다. 이런 방법을 사용할 때, 하류에서 the marker outline has little to do with the boundary of the turbulent domain. 우선 마커가 빠르게 번져서 국소적 유동을 선명히 볼 수 없다. 마커는 입자가 지나온 전 과정의 history를 모두 반영한다. 또 난류에 의해 마커의 선명함뿐 아니라 농도도 퍼진다. 심지어 층류 유동에서도 vortex boundary와 많은 차이를 보일 수 있다. 유동 가시화는 보충의 역할로서 수행되어야 한다.</p>

<h3 id="dejinition-and-characteristics-of-coherent-structures">Dejinition and characteristics of coherent structures</h3>
<p><strong>There is as yet no consensus in what is meant by coherent structures</strong>. Most researchers
have seen pictures of structures in a mixing layer. 원칙적으로 난류 구조와 같은 개념은 암묵적으로 두는 것이 최선이다. 하지만 난류 구조를 측정하고 그들의 역학을 평가하기 위해서는 난류 구조에 대한 정의를 세워야 한다.</p>

<p><strong>A coherent structure is a connected turbulent fluid mass with instantaneously phase-correlated vorticity over its spatial extent</strong>. That is, underlying the random, three-dimensional vorticity that characterizes turbulence, there is a component of large-scale vorticity which is instantaneously coherent over the spatial extent of a coherent structure Coherent vorticity is the primary identifier of coherent structures, which have distinct boundaries and independent territories.</p>

<p>이러한 정의에 의해, 난류 유동은 coherent / in-coherent structure로 분해될 수 있다. 앙상블 평균을 내면 in-coherent 구조는 날아가고 coherent 구조를 특징지을 수 있다. The ensemble average of appropriately phase-aligned realizations containing similar organized events is a coherent structure; whatever is not included in the ensemble average is incoherent turbulence.</p>]]></content><author><name>bear11235</name></author><category term="study" /><category term="turbulence" /><summary type="html"><![CDATA[Coherent structures and turbulence (1968) Journal of Fluid Mechanics (1986) Author: FAZLE HUSSAIN]]></summary></entry><entry><title type="html">Turbulence Equations</title><link href="http://localhost:4000/study/turbulence/turbulence/" rel="alternate" type="text/html" title="Turbulence Equations" /><published>2023-05-12T00:00:00+09:00</published><updated>2023-05-12T00:00:00+09:00</updated><id>http://localhost:4000/study/turbulence/turbulence</id><content type="html" xml:base="http://localhost:4000/study/turbulence/turbulence/"><![CDATA[<h1 id="types-of-turbulence">Types of Turbulence</h1>
<h2 id="statistically-homogeneous-turbulence">Statistically Homogeneous Turbulence</h2>
<ul>
  <li>All statistics of fluctuating quantities are invariant under translation of the coordinate system</li>
  <li>어디에서 난류 유동의 통계량을 측정해도 같은 값을 가짐</li>
  <li>모든 곳에서 평균 속도에 대한 gradient는 0이어야 하고, 따라서 모든 곳에서 평균 속도는 모두 0을 가짐</li>
  <li>Kolmogorov hypotheses: Turbulent motions on small scales are typically assumed to be isotropic</li>
</ul>

<figure class="third center">
  <img src="/assets/images/posts/linux/Turbulence/introduction/01.png" />
  <figcaption>DNS of statistically homogeneous and isotropic turbulence: x1-component of the velocity
</figcaption>
</figure>

<h2 id="turbulent-shear-flow">Turbulent Shear Flow</h2>
<ul>
  <li>Relevant flow cases in technical systems
    <ul>
      <li>Round jet</li>
      <li>Flow around airfoil</li>
      <li>Flows in combustion chamber</li>
    </ul>
  </li>
  <li>Due to the complexity of these turbulent flows they cannot be described theoretically</li>
</ul>

<figure class="third center">
  <img src="/assets/images/posts/linux/Turbulence/introduction/02.png" />
  <img src="/assets/images/posts/linux/Turbulence/introduction/03.png" />
  <figcaption>
  Temporally evolving shear layer“: Scalar dissipation rate χ (left), mixture fraction Z (rechts)
</figcaption>
</figure>

<h1 id="equations">Equations</h1>
<h2 id="mean-flow-equations">Mean-flow Equations</h2>
<ul>
  <li>Averaged Momentum Equation</li>
</ul>
<figure class="two-third center" style="margin: 0 0">
  <img src="/assets/images/posts/linux/Turbulence/introduction/04.png" />
</figure>

<p>The last term is defined as Reynolds stress tensor:</p>

\[\tau_{ij,turb}=-\rho \overline{u'_i u'_j}\]

<h2 id="reynolds-stress-equations">Reynolds Stress Equations</h2>
<figure class="two-third center" style="margin: 0 0">
  <img src="/assets/images/posts/linux/Turbulence/introduction/05-1.png" />
  <img src="/assets/images/posts/linux/Turbulence/introduction/05-2.png" />
</figure>

<p><strong>Physical meaning of each term</strong></p>
<ul>
  <li>\(L\): Local change</li>
  <li>\(C\): Convective transport</li>
  <li>\(P\): Production of Reynolds stresses (negative product of Reynolds-stress tensor and the gradient of time-averaged velocity)</li>
  <li>\(DS\): (Pseudo-)dissipation of Reynolds stresses</li>
  <li>\(PSC\): pressure-rate-of-strain correlation. It contributes to the redistribution of Reynolds stresses in a similar way the diffusion term does</li>
  <li>\(DF\): diffusion of the Reynolds stresses. It includes all terms under the divergence operator</li>
</ul>]]></content><author><name>bear11235</name></author><category term="study" /><category term="turbulence" /><summary type="html"><![CDATA[Types of Turbulence Statistically Homogeneous Turbulence All statistics of fluctuating quantities are invariant under translation of the coordinate system 어디에서 난류 유동의 통계량을 측정해도 같은 값을 가짐 모든 곳에서 평균 속도에 대한 gradient는 0이어야 하고, 따라서 모든 곳에서 평균 속도는 모두 0을 가짐 Kolmogorov hypotheses: Turbulent motions on small scales are typically assumed to be isotropic]]></summary></entry><entry><title type="html">[ML/DL] Gaussian Process 공부하기</title><link href="http://localhost:4000/study/ml-dl/gaussian-process/" rel="alternate" type="text/html" title="[ML/DL] Gaussian Process 공부하기" /><published>2023-04-28T00:00:00+09:00</published><updated>2023-04-28T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/gaussian-process</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/gaussian-process/"><![CDATA[<h1 id="learning">Learning</h1>

<h2 id="log-likelihood-of-mvn">Log-Likelihood of MVN</h2>
<p>GP를 실제 데이터에 적용하면 우리가 얻게되는 데이터의 형태는 Multi-Variate Normal(MVN) 분포를 따르게 된다. n차원의 MVN 분포를 생각해보자. 평균은 n차원의 벡터로, 공분산은 \(n \times n\)의 행렬로 표현된다.</p>

\[\mathbf{X}\sim \mathcal{N_n}(\mathbf{\mu}, \mathbf{\Sigma}) \quad \text{where} \quad \mathbf{\mu} \in \mathcal{R}^n, \mathbf{\Sigma} \in \mathcal{R}^{n \times n}\]

<p>그리고 위 분포의 pdf는 아래와 같이 정의된다.</p>

\[p(\mathbf{x; \mu, \Sigma}) = (2 \pi)^{-n/2} \det{(\mathbf{\Sigma})}^{-1/2} \exp{\left(-\frac{1}{2} \mathbf{(x-\mu)^T \Sigma^{-1} (x-\mu)}\right)}\]

<p>평균과 공분산을 파라미터 \(\mathbf{\Theta}\)로 생각하면 log-likelihood 함수를 아래와 같이 계산할 수 있다.</p>

\[\mathcal{L}(\mathbf{\Theta}) = \log p(\mathbf{x}; \mathbf{\Theta}) = 
-\frac{n}{2}\log(2\pi) -\frac{1}{2}\det{\mathbf{\Sigma}} -\frac{1}{2} \mathbf{(x-\mu)^T \Sigma^{-1} (x-\mu)}\]

<p>만약 prior mean을 0으로 생각한다면 조금 단순해진다.</p>

\[\mathcal{L}(\mathbf{\Theta}) = -\frac{n}{2}\log(2\pi) -\frac{1}{2}\det{\mathbf{\Sigma}} -\frac{1}{2} \mathbf{x^T \Sigma^{-1} x}\]

<h2 id="marginal-log-likelihood-in-gp">Marginal Log-Likelihood in GP</h2>
<p>Gaussian Process는 프로세스 안에서 어떠한 subset을 골라도 gaussian distribution을 따르기 때문에, 우리가 관심있는 index에 대해서 marginalize하기 쉽다. 이를 Marginal Log-Likelihood(MLL)이라 하자. GP를 통해 찾고자하는 latent function variable(?) 혹은 참이라고 추정하는 함수값을 \(\mathbf{f}\)라고 하자. 실제 그 함수가 우리에게 발현되어 관측되는 값은 노이즈가 섞인 값이다. 관측되는 값을 \(\mathbf{y}\)라고 하자. 우리가 학습하는 과정에서 활용하는 데이터는 실제 측정된 데이터이므로 \(\mathbf{f}\)보단 \(\mathbf{y}\)라고 생각해야 한다. 따라서 우리가 구하고자 하는 likelihood 값은 아래와 같다. GP를 학습하기 위해서 위 MLL 값을 최대화, 혹은 negative MLL을 최소화한다.</p>

\[\begin{align}
\mathcal{L}(\mathbf{\Theta}) &amp;= p(\mathbf{y}\vert\mathbf{x}; \mathbf{\Theta}) \\
&amp;= \int{p(\mathbf{y \vert f}) p(\mathbf{f \vert x}) d\mathbf{f}} \\
&amp;= -\frac{n}{2}\log(2\pi) -\frac{1}{2}\log(\det{(\mathbf{\Sigma} + \sigma_n^2\mathbf{I})}) -\frac{1}{2} \mathbf{x^T (\mathbf{\Sigma} + \sigma_n^2\mathbf{I})^{-1} x} \\
&amp;= -\frac{n}{2}\log(2\pi) -\frac{1}{2}\log(\det{\mathbf{\Sigma'}}) -\frac{1}{2} \mathbf{x^T (\Sigma')^{-1} x}
\end{align}\]

<p>MLL을 계산할 때, Covariance Matrix가 가진 성질을 바탕으로 Cholesky decomposition을 활용해 직접 역행렬과 행렬식을 구하는 것보다 빠르게 구할 수 있다. Symmetric Semi-Positive Definite Matrix \(K\)에 대해서 아래와 같은 cholesky decomposition이 가능하다.</p>

\[K = LL^T = L^TL  \quad \text{where} \quad L \text{ is triangular matrix}\]

<p>우리가 다루는 Covariance Matrix는 위 조건을 만족하므로 cholesky decomposition이 가능하고, 위에서 정리한 MLL은 아래와 같이 전개된다.</p>

\[\begin{align}
\mathcal{L} &amp;\propto -\frac{1}{2}\log(\det{\mathbf{\Sigma'}}) -\frac{1}{2} \mathbf{y^T (\Sigma')^{-1} y} \\
&amp;= -\frac{1}{2}\log(\det{(\mathbf{L L}^T)}) -\frac{1}{2} \mathbf{y^T L^{-T} L^{-1} y} \\
&amp;= -\log(\det{\mathbf{L}}) -\frac{1}{2} \mathbf{y^T L^{-T} L^{-1} y} \\
&amp;= -\sum_{i=1}^{n} \log L_{ii} -\frac{1}{2} \mathbf{\alpha}^T \mathbf{\alpha}, \qquad \text{where } \alpha =\mathbf{L}\backslash\mathbf{y}\\
\end{align}\]]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="Gaussian Process" /><category term="GP" /><summary type="html"><![CDATA[Learning]]></summary></entry><entry><title type="html">Remote access with SSH tunneling</title><link href="http://localhost:4000/linux/cluster/remote-access-via-ssh-tunneling/" rel="alternate" type="text/html" title="Remote access with SSH tunneling" /><published>2023-04-23T00:00:00+09:00</published><updated>2023-04-23T00:00:00+09:00</updated><id>http://localhost:4000/linux/cluster/remote-access-via-ssh-tunneling</id><content type="html" xml:base="http://localhost:4000/linux/cluster/remote-access-via-ssh-tunneling/"><![CDATA[<h1 id="개요">개요</h1>
<p>이 포스트는 보안 상의 이유로 인바운드 포트가 막혀있을 때, 이를 ssh tunneling을 통해 우회하여 통신하는 방식에 대해 소개한다.</p>

<h1 id="cluster-configuration">Cluster Configuration</h1>
<p>현재 우리 연구실의 컴퓨터 클러스터 시스템은 아래 사진과 같이 구성되어 있다. 모든 CPU 및 GPU 컴퓨터, NAS, Switch 등은 코로케이션이라는 곳에 위치하고 있다. 기본적으로 서울대학교는 일부 포트(80, 443, 22 등)에 대해서 외부로부터 교내망으로의 인바운드를 막고 있고, 교내망 내부에서는 포트 제한을 두고 있지 않다. 하지만 코로케이션은 그보다 더욱 강화된 보안을 가져, 교내 교외 상관없이 코로케이션은 모든 아웃바운드 포트는 열려있지만, 모든 인바운드 포트는 막혀있다. 학교 안이라도 기본적으로는 코로케이션에 접근이 안 되는 것이다. 이런 상황에서 아래 조건을 만족하도록 원격 접속을 허용하고자 한다.</p>
<ul>
  <li>연구실 구성원은 사용하는 포트에 대해 제한 없이 접속 가능하도록</li>
  <li>구성 이후 새롭게 추가되는 client pc도 쉽게 접속할 수 있도록</li>
  <li>관리자의 허가 하에, 모든 외부망에서의 접속 가능하도록</li>
</ul>

<p><img src="/assets/images/posts/linux/remote-access-via-ssh-tunneling/01.jpg" style="width: 80%" /></p>

<h2 id="step-1-using-a-router">Step 1. Using a router</h2>
<p>우선 코로케이션으로의 모든 인바운드 포트가 막혀있으므로, 외부 접속을 할 수 있도록 별도의 허가가 필요하다. 그런데 이 과정이 매우 불편하고 보수적(?)인데, (server ip, server port to be opened, client ip) 세 개의 순서쌍으로 신청을 해야 한다. 클러스터에서 접속해야하는 서버 ip가 대략 20개, 각 ip에 대해 열어야하는 포트가 평균 5개, 클라이언트 ip가 대략 20개이므로 \(20\times5\times20=2000\)개의 신청을 해야한다. 일일이 이 모든 순서쌍을 신청하는 것은 아래의 문제들이 있다.</p>
<ol>
  <li>학교에서 이 정도 숫자의 신청은 안 받아줄 수 있다</li>
  <li>클라이언트 ip는 추가/제거/변경되므로 지속적으로 변한다</li>
  <li>포트 오픈 신청을 교수님 계정으로 해야 한다.</li>
</ol>

<p>한마디로, 학교에서 신청을 승인해줄지도 모르고, 해준다 하더라도 클라이언트 pc가 추가/제거/변경 될 때마다 교수님 계정으로 신청을 해야한다. 여간 번거로운게 아니다. 위 상황을 현실적으로 해결하기 위해 아래의 조치를 취했다.</p>
<ol>
  <li>서버에서 요구하는 포트는 거의 다 정해졌기 때문에 서버의 ip 및 포트는 건들지 않는다.</li>
  <li>클라이언트 pc들을 모두 dhcp 서버 기능을 하는 라우터 밑에 두고, 서버에 접속하는 ip는 라우터의 ip 하나로 한다. 이렇게 하면 연구실 내부에 새로운 클라이언트가 생겨도 어차피 라우터 밑으로 들어가기 때문에 서버와 통신할 때는 라우터를 거쳐 통신하기 때문에 라우터 망 내부 아이피와 상관없이 서버와 통신할 수 있다.</li>
  <li>외부망 접속을 위해 ssh tunneling 설정을 한다.</li>
</ol>

<p>연구실이 총 2개이기에 라우터 A와 라우터 B가 있다. 서버와 통신하는 클라이언트는 라우터 2개 뿐이므로 승인받는 순서쌍의 갯수가 200개로 줄어든다. 그리고 만약 추후에 서버가 추가됐을 때에도 2개 라우터에 대해서만 추가로 승인받으면 된다. 연구실 컴퓨터를 모두 라우터 밑으로 두게 되면 연구실에서 서버로의 접속은 미리 신청한 포트에 대해서는 제한없이 접속가능하게 된다. 물론 이렇게되면 외부에서 연구실 컴퓨터로 통신하기 위해서는 라우터에서 포트포워딩을 해줘야 한다. 연구실 컴퓨터가 많아야 10개라 이 정도는 수동으로 설정하면 되기에 문제가 되지 않는다.</p>

<h2 id="step-2-ssh-터널링-용-ssh-server-configuration">Step 2. ssh 터널링 용 ssh server configuration</h2>
<p>위 과정만으로는 라우터 내부망 밖에서는 서버로의 접속이 불가능하다. 외부에서의 접속을 위해 고려한 사항이 2가지인데, 하나는 라우터에 vpn서버를 돌리고 외부에서 vpn을 통해 서버로 접속하는 것, 다른 하나는 ssh tunnel을 이용하는 것이다. 처음에는 vpn을 이용하려고 vpn router를 구매했는데도 속도나 안정성 면에서 생각만큼 안정적이진 못했다. 그래서 결국 ssh tunnel을 이용하게 되었다. 결론적으로 ssh tunnel을 이용하니 더욱 안정적이고 빠른 연결을 구성할 수 있었다.</p>

<p>개요는 이렇다. 라우터 밑에, 즉 연구실 내부망에 24시간 돌아가는 ssh server를 구동한다. 그리고 외부에서 해당 ssh server로 접속할 수 있도록 ssh server와 그 위에 있는 라우터를 설정한다. ssh server는 승인 받은 router 밑에 있으므로 사용하고자 하는 포트에 대해 서버로 접속할 수가 있다. 마지막으로 외부에서 ssh server로 접속하고 ssh 터널링을 통해 접속하고자 하는 서버에 접속한다.</p>

<p>나는 라우터 밑에 있는 ssh 서버를 Synology nas로 구성하였다. 어차피 연구실 내부에서도 nas가 있으면 좋기도 하고, 24시간 돌리기에 일반 컴퓨터는 불안했다. Synology nas에서 ssh service를 활성화하고, sshd_config 파일을 수정하여 터널링 기능을 켜주었다. 어차피 ssh server로의 접속은 라우터에서 포트포워딩을 통해 진행되기에 ssh server의 포트는 굳이 변경하지 않아도 된다. 외부에서 ssh server로 접속하기 위해서는 라우터 단에서 포트포워딩을 설정해야 한다. 라우터는 교내 망에 있기 때문에 기본적으로 22번 포트의 인바운드가 막혀있다. 따라서 인바운드가 막혀있지 않은 포트(ex 12345번)를 ssh server로 ssh port(ex 22번)로 포워딩하도록 한다. 이렇게 하면 임의의 외부망에서 12345번 포트를 이용하여 라우터에 접속하면 포트포워딩을 통해 ssh server로 접속할 수 있게 된다.</p>

<h2 id="step-3-ssh-connection-with-ssh-tunneling">Step 3. ssh connection with ssh tunneling</h2>
<p>step 2에서 설정한 ssh server에 접속할 때, <code class="language-plaintext highlighter-rouge">ssh -L local_port:dest_host:dest_port</code> option을 통해 터널링 기능을 활성화한다. 터널링 옵션까지 주게 되면, ssh server로의 접속이 유지되는 동안 localhost:local_port로 접속하면 dest_host:dest_port로 접속할 수 있다.</p>

<h1 id="예시">예시</h1>
<p>라우터(A)의 ip를 AAA.AAA.AAA.AAA, 라우터 밑에 있는 ssh server(a)의 ip를 aaa.aaa.aaa.aaa, 접속하고자 하는 서버(B)의 ip를 BBB.BBB.BBB.BBB, 외부망에서 접속하고자 하는 클라이언트(X) ip를 XXX.XXX.XXX.XXX라고 하자. 서버 B에서 운영하는 서비스가 예를 들어 xrdp라고 하면, 포트는 3389가 될 것이다. 우선은 라우터 A에서 서버 B로의 포트 3389 인바운드는 미리 승인을 받아 열어준다. 이렇게 되면 ssh server a는 3389포트를 이용해 B로 접속할 수 있다. ssh server의 포트는 22라고 하고, router에서 ssh server로 포트포워딩 설정해준 외부 포트는 12345라고 하자. 외부 클라이언트 X가 서버 B로 접속하기 위해서는 아래와 같은 옵션을 통해 ssh server로 접속을 한다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh AAA.AAA.AAA.AAA<span class="o">(</span>router ip<span class="o">)</span> <span class="nt">-p</span> 12345<span class="o">(</span>port-forwarding port<span class="o">)</span> <span class="nt">-L</span> 33891<span class="o">(</span>local_port<span class="o">)</span>:BBB.BBB.BBB.BBB<span class="o">(</span>dest_host<span class="o">)</span>:3389<span class="o">(</span>dest_port<span class="o">)</span>
</code></pre></div></div>

<p>이렇게 되면 ssh 터널링이 활성화된 ssh 연결이 이루어진다. 지금 예시에서는 xrdp를 이용하고자 하니, rdp 프로그램을 실행시켜 localhost:33891로 접속하게 되면 결과적으로 BBB.BBB.BBB.BBB:3389로 접속이 된다.</p>

<h1 id="마무리">마무리</h1>
<p>위와 같은 방식으로 현재 외부망에서 서버로의 ssh, rdp, smb, nfs 등의 서비스를 이용하고 있다. 여러 면에서 단점보다 장점이 많은 것 같다. 안정성의 경우, 아직까지 n시간 이용 시 연결이 끊긴 적은 없다. vpn 사용할 때는 1시간 정도 사용하면 연결이 끊겼는데, 이에 비하면 굉장히 안정적인 모습이다. 속도 또한 만족스러운데, 교내는 기가 인터넷으로 구성이 되어 있어 최대 대역폭은 1Gbps이지만 ssh tunnel을 이용하면 한 300Mbps 정도 나오는 것 같다. 애초에 외부에서 접속한다면 카페 등에서 wifi 접속하는 경우가 많을텐데 300Mbps의 속도는 충분하다. 또한 터널링 과정에서 localport는 사용자가 직접 설정하기 때문에 사용자가 좋아하는 포트를 사용할 수 있다는 것도 좋은 점 같다.</p>

<p>하지만 이 방법은 어쨋든 외부에서 서버로 접속을 허용하는 방법이기에 보안에 취약하다. 애초에 모든 인바운드를 막아놓은 이유에 대해 생각해보면 좋겠다. 나 같은 경우는 ssh server에 접속할 수 있는 계정에 대해 제한을 두고, 포트 등을 기본값 대신 다른 값을 이용하는 등의 방법으로 보안을 강화하였다. 이런 방식의 우회 방법은 언제나 외부 공격에 대해 경각심을 가지고 진행해야 함을 잊지 말자. 이런 포스트 등을 포함하여 외부에 ip 및 port, account 정보 등은 공개하지 않는 것이 좋다.</p>]]></content><author><name>bear11235</name></author><category term="linux" /><category term="cluster" /><category term="linux" /><category term="cluster" /><category term="firewall" /><category term="ssh" /><summary type="html"><![CDATA[개요 이 포스트는 보안 상의 이유로 인바운드 포트가 막혀있을 때, 이를 ssh tunneling을 통해 우회하여 통신하는 방식에 대해 소개한다.]]></summary></entry><entry><title type="html">Explainable AI (LIME, SHAP) 공부하기</title><link href="http://localhost:4000/study/ml-dl/explainable-AI/" rel="alternate" type="text/html" title="Explainable AI (LIME, SHAP) 공부하기" /><published>2023-04-23T00:00:00+09:00</published><updated>2023-04-23T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/explainable-AI</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/explainable-AI/"><![CDATA[<p>AI의 모델</p>
<ul>
  <li>Rule-based system: 사람이 일일이 프로그램하여 컴퓨터는 주어진 규칙대로 계산만 수행.</li>
  <li>Classic ML-DL: 사람이 feature를 디자인하고, 컴퓨터는 feature를 매핑한다.</li>
  <li>Deep Learning: 더욱 복잡한 feature를 모델이 찾는다.</li>
</ul>

<p>일반적으로 explainability가 높다는 것은 모델의 complexity가 낮다는 것이고, 이는 모델의 capacity or performance가 낮음을 의미한다. 그래서 복잡한 DL의 경우, black-box처럼 생각되는 경우가 많다.</p>

<p>Need for explainable AI</p>
<ul>
  <li>Explain to Justify: 시스템의 행동 이유에 대한 정당성.</li>
  <li>Explain to Improve: 시스템의 성능 개선을 위해서.</li>
  <li>Explain to Discover: DL은 사람이 찾지 못하는 패턴들을 잘 찾는다. 그 패턴을 이해하기 위해.</li>
  <li>Explain to Control: 모델의 적절한 제어를 위해.</li>
</ul>

<p>설명가능한 AI를 통해 아래의 질문에 답하고자 함.</p>
<ul>
  <li>왜 그렇게 했는지?</li>
  <li>왜 다른 행동은 안 했는지?</li>
  <li>언제 성공/실패를 하는지?</li>
  <li>언제 결과를 신뢰해도 괜찮은지?</li>
  <li>어떻게 에러를 수정할지?</li>
</ul>

<h1 id="설명-가능성의-종류">설명 가능성의 종류</h1>
<h2 id="설명-가능함의-시점">설명 가능함의 시점</h2>
<ul>
  <li>Ante-hoc (build a new learning model)
    <ul>
      <li>모델을 만들 때부터 설명가능하게끔 만든다.</li>
    </ul>
  </li>
  <li>Post-hoc (explain the black-box)
    <ul>
      <li>블랙박스 형태의 모델을 생성한 후에, 그 블랙박스 모델을 새로운 방식을 통해 설명하고자 함.</li>
    </ul>
  </li>
</ul>

<h2 id="모델-제한적">모델 제한적</h2>
<ul>
  <li>Model-specific
    <ul>
      <li>어떤 구체적인 아키텍쳐의 모델에 대해 사용 가능</li>
      <li>모델 자체가 설명 가능함을 지닌 경우</li>
      <li>어떤 경우에는 모델 성능에 영향을 준다.</li>
    </ul>
  </li>
  <li>Model-agnostic
    <ul>
      <li>일반적인 블랙박스 모델에 사용 가능</li>
      <li>기존 모델은 그대로 두고, 추후 설명 가능함을 위한 모듈을 추가하는 형식이라 블랙박스 모델 성능에 영향을 주지 않음.</li>
    </ul>
  </li>
</ul>

<h2 id="국지성">국지성</h2>
<ul>
  <li>Global interpretability
    <ul>
      <li>모델 전체를 보고, 해당 모델이 전반적으로 어떤 행동을 할지 설명 가능함.</li>
      <li>예를 들어, decisition tree를 보면 전체적인 모델의 행동 양상이 보인다.</li>
    </ul>
  </li>
  <li>Local interpretability
    <ul>
      <li>어떤 입력값에 대한 모델의 결과를 설명 가능함.</li>
      <li>예를 들어 복잡한 사진을 주고 물체를 구분하는 작업에서 사진 내 픽셀에 대한 각 카테고리 별 확률 분포 제시.</li>
    </ul>
  </li>
</ul>

<p><strong>Sensitivity Analysis (SA)</strong></p>

<p>모델에 영향을 많이 주는 입력값은, 출력값을 입력값으로 미분했을 때, gradient 값이 큰 입력값이다. 예를 들어 모델에 사진을 넣었고, 모델은 고양이라는 답을 주었다면 그 답에 영향을 많이 미치는 입력 픽셀은 큰 gradient를 가질 것이다(?) 진짜 그럴려나.. 만약 사진을 입력으로 넣은 경우를 생각해보자. 사진을 보고 카테고리를 분류하는 모델이 어떤 한 사진을 입력으로 받고 고양이라는 답을 내놓았다. 모델의 출력에 x라는 점들이 영향을 가장 크게 주었다면, 만약 x 점들이 이상한 값으로 될 경우, 모델이 고양이라는 답을 내놓지 않을 것이다.</p>

<p><strong>Layerwise Relevance Propagation (LRP)</strong></p>

<p>어떤 결과가 나왔을 때, 입력값을 기준으로 얼마나 contribution이 있는지 역추적하는 느낌? FCNN을 생각해볼 때, 마지막 hidden layer 내 노드 중, 출력값에 가장 큰 영향을 주는 노드를 찾을 수 있을 것이다. 또 해당 layer에 영향을 주는 정도를 이전 layer의 노드들에 대해 계산할 수 있을 것이고 이를 반복적으로 할 수 있을 것이다. 그렇게 출력값에 대한 입력값의 기여도를 계산할 수 있다.</p>

<h1 id="lime">LIME</h1>
<p>Local Interpretable Model-agnostic Explanations</p>

<p>예시를 먼저 보자. 어떤 모델이 sneeze, weight, headache, no fatigue, age의 feature를 보고 flu를 판단한다고 하자. LIME이 하고 싶은 것은 flu라는 답에 대해 어떤 features가 얼마나 영향을 끼쳤는지를 보는 것이다.</p>

<p>LIME은 다음 4개의 basic criteria를 만족해야 함:</p>
<ol>
  <li>Interpretable: 쉽게 설명 가능해야 한다.</li>
  <li>Local fidelity: 임의의 instance에 대해서 설명을 할 때, local behavior를 잘 설명해야 한다.</li>
  <li>Model-agnostic: 임의의 모델에 대해 잘 작동해야 한다.</li>
  <li>Global perspective: 전체적인 거동도 어느 정도 설명해야 한다(?)</li>
</ol>

<h1 id="shap">SHAP</h1>
<p>SHapley Additive exPlanation의 약자.</p>

<h2 id="shapley-value">Shapley Value</h2>
<p>게임 이론에서 등장하는 개념. Total payout을 도출하기 위한 각 개인의 기여도를 계산하는 방식. 예를 들어 A,B가 팀 과제를 하는 상황이다. A 혼자하면 70점을 맞고, B 혼자하면 80점을 맞고, A와 B가 같이 하면 100점을 맞는다고 하자. 둘이 같이 하여 100점을 맞았을 때 A, B의 기여도는 어떻게 되는 것인가? 이러한 질문에 사용되는 개념이다. 출력값에 대한 입력값의 영향이 비선형적으로 결합이 될텐데, 그것을 decompostion하는 방식이라고 보면 좋을 듯.</p>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="AI" /><category term="LIME" /><category term="SHAP" /><summary type="html"><![CDATA[AI의 모델 Rule-based system: 사람이 일일이 프로그램하여 컴퓨터는 주어진 규칙대로 계산만 수행. Classic ML-DL: 사람이 feature를 디자인하고, 컴퓨터는 feature를 매핑한다. Deep Learning: 더욱 복잡한 feature를 모델이 찾는다.]]></summary></entry><entry><title type="html">t-SNE 공부하기</title><link href="http://localhost:4000/study/ml-dl/SNE/" rel="alternate" type="text/html" title="t-SNE 공부하기" /><published>2023-04-22T00:00:00+09:00</published><updated>2023-04-22T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/SNE</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/SNE/"><![CDATA[<h1 id="sne">SNE</h1>
<p>Stochastic Neighbor Embedding의 약자. 여기서 임베딩의 의미는 고차원에서 저차원으로 매핑한다는 말이다.</p>

<p>고차원 공간에 있는 데이터 포인트들 사이의 거리, 혹은 이웃인 정도를 확률로서 표현하고, 그 확률을 유지하도록 저차원 공간으로 매핑하는 것. 데이터 자체는 왜곡이 될 수 있지만, 데이터 사이의 가까운 정도는 최대한 유지하고 싶다. 여기서 학습이라는 것은 고차원 공간에서 저차원 공간으로 매핑하는 방법을 학습하는 것.</p>

<p>고차원에서 이웃의 정도를 결정하는 방법? -&gt; Squared Exponential 함수를 통해 거리를 측정하고 확률로 표현하기 위해서 normalize를 진행한다. n개의 데이터 포인트에 대해서 각각 n개의 데이터에 대한 이웃인 정도를 나타내기에 n by n 형태의 Neighbar Probability Matrix가 생성된다. 각 데이터 포인트 사이의 절대적 거리는 대칭적이지만, 기준이 되는 포인트에서 normalization constant는 다르기 때문에, probability matrix는 비대칭으로 표현될 수 있다.</p>

<h2 id="perplexity">Perplexity</h2>
<p>2 ** H(P_i)로 정의된다. 데이터끼리 뭉치고 흩어지는 정도를 정하는 파라미터. 대략 한 점에서 이웃이라고 생각하는 점의 개수라고 생각하면 될 듯.</p>

<h2 id="cost-function">Cost Function</h2>
<p>고차원과 저차원에서의 확률 행렬을 각각 P_ij, Q_ij라고 하면, 그 둘 사이의 차이값, 거리값, 괴리감은 확률 분포의 괴리를 표현하는 KL divergence로 표현한다.</p>

\[J = KL(P||Q)\]

<p>KL Divergence를 사용하면, gradient descent 방식에서 식이 쉽게 나온다.</p>

\[dJ/dy = sth\]

<p>gradient의 의미는? 이웃인 확률이 고차원 &gt; 저차원 이라면 저차원 공간에서 서로 가까이 당겨야하고, 반대로 고차원 &lt; 저차원 이라면 저차원 공간에서 서로 밀어야 한다. 또한 gradient의 크기가 저차원에서의 거리에 비례하기 때문에, 학습 과정에서 저차원 공간으로 매핑된 데이터들이 서로 뭉치게 된다.</p>

<p>실제 데이터들을 SNE를 통해 저차원으로 매핑하면, 데이터들끼리 좀 뭉치는 경향이 있다. 이를 보완하고자 t-SNE를 고안.</p>

<h1 id="t-sne">t-SNE</h1>
<p>t-SNE에서 t는 Student-t를 의미한다. 
기존 SNE보다 가까운 것은 더 가깝게, 먼 것은 더 멀게 표현하여 실제 데이터에 왜곡이 생길지라도 시각적으로 더 예쁘게 그리려고 함. SNE에서 이웃인 정도를 표현하기 위해 고차원과 저차원 공간에서 Gaussian 분포를 이용했다. 하지만 만약 저차원 공간에서 heavy-tailed distribution을 사용한다면? 고차원에서 가까운 점은 저차원에서 더 가까워지고, 고차원에서 먼 점은 저차원에서 더 멀어진다.</p>

<p>t-SNE에서 cost function에 대한 gradient는 기존 SNE에서의 값에 (1+d)^-1 값이 붙는다. 이는 저차원 공간에서 두 점의 거리가 멀어지면 gradient 값이 작아지고, SNE와는 다르게 거리가 어느 이상 멀어지면 서로 밀고 당기는 힘의 크기가 작아진다. 그로 인해 가까운 데이터들은 서로 당기게 되고, 어느 거리가 넘어가면 더 이상 당기는 힘이 증가하지 않고 locally attract하게 된다.</p>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><summary type="html"><![CDATA[SNE Stochastic Neighbor Embedding의 약자. 여기서 임베딩의 의미는 고차원에서 저차원으로 매핑한다는 말이다.]]></summary></entry><entry><title type="html">여러 Boosting 알고리즘 공부하기</title><link href="http://localhost:4000/study/ml-dl/boosting-algorthms/" rel="alternate" type="text/html" title="여러 Boosting 알고리즘 공부하기" /><published>2023-04-22T00:00:00+09:00</published><updated>2023-04-22T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/boosting-algorthms</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/boosting-algorthms/"><![CDATA[<h1 id="adaboost">AdaBoost</h1>
<p>Adaptive Boost의 약자로, 이름에서 알 수 있다시피 적응형이다. 
AdaBoost도 Boosting이므로 classifier를 순차적으로 학습한다. 첫번째 데이터셋에 대해 학습을 진행하고, 그 결과에 따라 다음 데이터셋에 적절한 가중치를 부여하고 다음 모델을 학습한다. 이때 데이터셋에 가중치는 어떻게 부여하는가? 또한 n개의 모델을 학습한 후에 각 모델들에 가중치를 두어 최종 모델을 구해야하는데, 이때도 각 모델에 대한 가중치를 어떻게 정할 것인가? 이 2개의 질문에 대한 답을 하는 것이 목적이다.</p>

<p>전체적인 흐름은 다음과 같다.</p>

<p>m번째 스텝에 대해 데이터 셋에 대한 가중치 \(w_m\)이 주어져 있다고 하자. 그리고 우리의 목적함수는 Exponential Loss의 형태를 가지는데, 그렇게 표현하는 이유는 loss의 축적이 더하기로 되는 것이 아닌 곱하기로 되게끔 하기 위함이다. Loss는 다음과 같이 표현된다.</p>

\[J_m = fcn(\alpha_m, w_m, f_m)\]

<p>먼저, 가중치가 고려된 m번째 데이터 셋에 대해 \(f_m\)을 학습한다. 학습이 완료된 m번째 모델 \(f_m\)을 기존 모델들과 잘 합쳐야하는데, 이는 \(\alpha_m\)을 결정하는 것이다. 이때 목적함수 \(J_m\)을 최소로 하는 \(\alpha_m\) 값을 찾으면 된다. 목적함수를 줄일 때는 gradient를 이용해서 찾는다.</p>

<p>장점:</p>
<ul>
  <li>빠르고 쉽다.</li>
  <li>반복 횟수에 대한 변수를 제외하면 parameter to tune이 없다.</li>
</ul>

<p>단점:</p>
<ul>
  <li>boosting 자체가 데이터 노이즈에 취약한 점이 있다.</li>
  <li>데이터가 부족하면 큰 효과가 없다.</li>
</ul>

<h1 id="gradient-boost">Gradient Boost</h1>

<p>Squared Loss에서 Gradient는 Residual(잔차)를 의미한다.</p>

<h1 id="xgboost">XGBoost</h1>

<p>Extreme Gradient Boost의 약자.</p>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="boosting" /><category term="ensemble" /><summary type="html"><![CDATA[AdaBoost Adaptive Boost의 약자로, 이름에서 알 수 있다시피 적응형이다. AdaBoost도 Boosting이므로 classifier를 순차적으로 학습한다. 첫번째 데이터셋에 대해 학습을 진행하고, 그 결과에 따라 다음 데이터셋에 적절한 가중치를 부여하고 다음 모델을 학습한다. 이때 데이터셋에 가중치는 어떻게 부여하는가? 또한 n개의 모델을 학습한 후에 각 모델들에 가중치를 두어 최종 모델을 구해야하는데, 이때도 각 모델에 대한 가중치를 어떻게 정할 것인가? 이 2개의 질문에 대한 답을 하는 것이 목적이다.]]></summary></entry><entry><title type="html">Ensemble Method 공부하기</title><link href="http://localhost:4000/study/ml-dl/ensemble-method/" rel="alternate" type="text/html" title="Ensemble Method 공부하기" /><published>2023-04-22T00:00:00+09:00</published><updated>2023-04-22T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/ensemble-method</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/ensemble-method/"><![CDATA[<h1 id="preliminary-knowledge">Preliminary Knowledge</h1>
<h2 id="bootstrap-요약">Bootstrap 요약</h2>
<p>Bootstrap (부트스트랩)은 데이터 내에서 반복적으로 샘플을 사용하는 resampling 방법 중 하나.</p>

<p>Bootstrap sampling을 하면 애초에 한 개 밖에 없었던 우리들의 sample data set을 n개의 sample data set을 가지고 있는 것과 같은 효과를 누릴 수 있게 한다. 이를 통해 우리는 data의 variance를 상당히 잘 근사 할 수 있는 결과를 볼 수 있다.</p>

<p>전체 크기가 n개인 원래의 데이터셋 S가 있다고 하자. S를 통해 크기가 N개인, 기존보다 더 큰 데이터셋 S’을 얻고 싶을 때, 부트스트랩 샘플링을 할 수 있다. 원래 데이터셋 S에서 복원 추출을 통해 m개를 뽑는다. 그렇게 뽑은 하나의 데이터셋을 \(s_i\)라고 하자. 이러한 복원추출을 N번 반복한다. 그러면 \(S'=\{s_1, \cdots, s_N \}\)의 새로운 데이터 셋을 구할 수 있다.</p>

<p>부트스트랩을 통해 얻어진 새로운 데이터 셋은 기존의 데이터 셋과 비슷한 분포를 가진다.</p>

<h1 id="ensemble-model">Ensemble Model</h1>

<p>강력한 하나의 모델 대신, 여러 개의 간단한 모델을 만들고 그들을 조합하여 예측하는 것.
예를 들어 Classifier를 만든다고 생각할 때, 엄청 복잡한 하나의 모델을 만들기보다는 간단한 classifer들을 만들고, 결과를 내야할 때 각 classifer에게 물어보고, 그것들의 대답 비율을 따져 최종 결정을 내리는 것.</p>

<p>대표적인 앙상블 유형에는 다음이 있다: Voting, Bagging, Boosting.</p>

<h2 id="bagging">Bagging</h2>

<p>Bootstrap Aggregation의 약자로, 샘플을 여러 번 뽑아(Bootstrap) 각 모델을 학습시켜 결과물을 집계(Aggregration)하는 방법이다. 원래 데이터 셋에서 작은 여러 개의 데이터 셋을 샘플링한다(bootstrap). 각 데이터 셋으로 모델을 학습시킨다. 그리고 학습된 모델의 결과를 집계하여 최종 결과 값을 구한다(Aggregation).</p>

<p>Categorical data는 각 모델들이 말한 catogory의 빈도수를 확인하고, 가장 많이 나온 결과를 채택하면 된다. Regression과 같이 continuous data를 다루는 경우, 각 모델들의 결과를 평균낼 수 있다.</p>

<h2 id="voting">Voting</h2>

<p>Voting은 Bagging과 비슷하게, 부트스트랩을 통해 구해진 여러 데이터 셋을 이용한다. 하지만 Bagging은 각 데이터 셋에 같은 알고리즘의 모델을 사용한다면, Voting은 각 데이터 셋에 대해 다른 알고리즘의 모델들을 사용하고, 각 모델이 자신만의 알고리즘으로 답한 결과를 이용하여 최종 결과를 도출한다. 예를 들어 분류 문제에서 Voting은 각 데이터 셋에 대해 KNN, SVM, Linear Regression 등의 알고리즘을 사용할 수 있다.</p>

<h2 id="boosting">Boosting</h2>

<p>Bagging에서는 부트스트랩을 통해 얻어진 데이터 셋에 대해 각각의 모델들이 “독립적으로” 학습하게 된다. 하지만 Boosting에서는 이전 모델의 학습이 다음 모델의 학습에 영향을 미친다. 이전 모델의 학습 결과에 대해 오답 데이터에는 더 큰 가중치를 두어, 새로운 모델은 이전에 모델이 틀린 부분에 대해 조금 더 집중해서 학습하게 된다. Bagging은 병렬적인 과정이라면, Boosting은 순차적인 과정이다.</p>

<h1 id="characteristics-of-ensemble-model">Characteristics of Ensemble Model</h1>

<ul>
  <li>Bias를 줄인다. 쉬운 모델들을 중첩하여 하나의 모델을 만들기 때문에 dicision boundary가 부드럽게 형성된다. 그렇게 모델의 복잡도를 늘리기 때문에 모델의 bias가 작아진다.</li>
  <li></li>
</ul>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="boost" /><category term="learning" /><summary type="html"><![CDATA[Preliminary Knowledge Bootstrap 요약 Bootstrap (부트스트랩)은 데이터 내에서 반복적으로 샘플을 사용하는 resampling 방법 중 하나.]]></summary></entry><entry><title type="html">Kernel method 공부하기</title><link href="http://localhost:4000/study/ml-dl/kernel-method/" rel="alternate" type="text/html" title="Kernel method 공부하기" /><published>2023-04-20T00:00:00+09:00</published><updated>2023-04-20T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/kernel-method</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/kernel-method/"><![CDATA[<h1 id="linear-regression-with-non-linear-features">Linear Regression with Non-linear Features</h1>

<p>어떤 데이터 x를 다루고 싶을 때, 그 x를 그대로 모델의 입력값으로 사용할 수도 있지만, 어떤 \(y=f(x)\)라는 매핑을 통해 일차적으로 변환을 하고, 그 이후에 모델에 집어넣을 수 있다. 예를 들어 x를 n차 다항식 형태로 매핑을 한다고 생각해보자.</p>

\[y = w_0x_0 + \cdots w_nx_n = [w_0, \cdots, w_n]^T \cdot [x^0, \cdots, x^n] = \mathbf{w \cdots x}\]

<p>linear regression에서 선형성은 파라미터 \(w\)에 대한 선형성이다. \(x\)는 다항함수를 지나기 때문에 선형성이 유지되진 않지만, 모델은 \(w_i\)에 대해 1차로 구성되어 있기 때문에 파라미터에 대한 선형성을 가지고 있다. 이때 어떤 변환을 거쳐야 하는지는 데이터의 특성과 밀접한 관련이 있다.</p>
<ul>
  <li>주기적인 데이터를 가진 경우는 \(sin / cos\) 등과 같은 harmonic function 등을 사용할 수 있다.</li>
  <li>고차항이 필요하다면 다음의 변환을 생각해볼 수 있다.</li>
</ul>

\[\phi(x) = [1, x, x^2, \cdots ]\]

<ul>
  <li>변수 사이의 상관 관계가 있다면 다음 변환</li>
</ul>

\[\phi(x) = [1, x_{1}x_{2}, x_{3}x_{4}, \cdots]\]

<p>이 방법에서 핵심은 non-linear feature + linear model이라는 것. 즉 변수는 비선형 변환을 통해 복잡한 패턴을 잡아낼 수 있지만 모델 자체는 선형이기 때문에 다루기 쉽다. 위에 예시에서 보듯 보통 feature를 생성할 때는 원래 데이터보다 더 고차원의 공간으로 매핑을 하게 된다. 이는 데이터를 다룰 때 계산량을 키우게 되는 단점을 가지고 있다. 이를 보안하기 위해 <strong>kernel method</strong>를 생각하게 되었다.</p>

<h1 id="kernel">Kernel</h1>

<h2 id="kernel-method">kernel method</h2>

<p>위 예시에서 나타난 공통점인데, input x는 feature로의 변환을 거치고, 그 변환된 feature들은 모델의 파라미터와 dot product를 하게 된다. kernel method는 중간 단계인 x-&gt;y로의 feature 변환을 건너 뛰려는 목적을 가지고 있다. 이를 <strong>kernel trick</strong>이라고 부른다. 이 커널 트릭을 통해 고차원으로의 변환을 찾거나 계산할 필요 없이, 바로 저차원의 데이터를 가지고 계산하면 된다. 쉽게 말해서 고차원의 데이터가 등장하는 중간 단계를 건너 뛰고 똑같은 계산 결과를 얻는 과정이다.</p>

<p>다음의 예시를 보자. 2차원 데이터 x,y에 대해 2nd order polynomial kernel \(k(x,y)=(x \cdot y)^2\)를 생각해보자. 커널 계산 결과는 다음과 같다. 우리는 2차원 데이터 x,y 만을 가지고 계산했지만 사실 그 과정에는 3차원으로의 매핑 -&gt; 내적 이라는 계산 과정이 들어간 것이다.</p>

\[k(x,y)=(x \cdot y)^2=(x_1 y_1 + x_2 y_2)^2 = (x_1^2, x_2^2, \sqrt{2} x_1 x_2) \cdot (y_1^2, y_2^2, \sqrt{2} y_1 y_2)\]

<h2 id="kernel-examples">kernel examples</h2>
<ul>
  <li>Linear Kernel: \(k(x,y) = x \cdot y\)</li>
  <li>Polynomial kernel: \(k(x,y) = (x \cdot y)^d or (x \cdot y + 1)^d\)</li>
  <li>Gaussian of RBF kernel: \(k(x,y) = \exp{(\frac{\vert x-y \vert}{2l^2})}\)</li>
</ul>

<h2 id="kernel-properties">kernel properties</h2>
<p>커널을 통해 feature transformation 계산을 하지 않아도 되는 것은 알겠는데, 그렇다면 특성으로의 변환과 커널 함수는 서로 일대일 대응이 되는지 궁금해진다. 즉 임의의 feature로의 변환을 생각했을 때 그에 대응되는 커널 함수 k가 있는지, 그리고 임의의 커널함수 k를 생각했을 때 그에 대응되는 feature가 있는지 말이다.</p>

<p>커널이 다음의 두 조건을 만족하면, 그에 대응되는 유일한 feature가 존재한다고 한다. 근데 실제로는 PSD가 아닌 커널 함수여도 충분히 유용한 커널 함수가 존재한다더라.</p>
<ul>
  <li>symmetric</li>
  <li>positive semi-definite (PSD)</li>
</ul>

<p>kernel은 다음과 같이 normalized 될 수 있다.</p>

<h1 id="algorithms-using-kernel">Algorithms Using Kernel</h1>
<p>선형 모델을 생각해보면 \(\mathbf{w^T x}\) 항이 등장한다. 이는 weight vector가 data와 같은 공간에 위치하는 것을 의미한다(중요).</p>

<h2 id="kernel-perceptron-algorithm">Kernel Perceptron Algorithm</h2>
<p>perceptron은 x를 인풋으로 받아 그 값을 +1/-1로 구분하는 단순한 모델. 
이것을 풀다보면 \(\mathbf{x \cdot x}\) 가 등장하는데, 이 항을 커널 함수로 바꾸는 알고리즘.
여기서 학습은 계수값인 \(\alpha\)를 업데이트 하는 것.</p>

<h2 id="kernel-linear-regression">Kernel Linear Regression</h2>
<p>Regression model에서 Ordinary Least Square(OLS)는 오차의 제곱을 최소로 하도록 하는 것.</p>

<p>Kernelization</p>

<p>우리가 찾고자 하는 solution of weight vector를 데이터 포인트의 linear combination으로 표현해보자.</p>

<p>\(\mathbf{w}=\sum_{i=1}{n}\alpha_i\mathbf{x_i}=\mathbf{X}\vec{\alpha}\)
\(\mathbf{w}=\mathbf{(XX^T)^{-1}Xy}\)</p>

<p>당연히 아직은 alpha값은 모르며, 학습을 통해 alpha를 업데이트 해갈 것이다. 가중치를 찾는 것은 alpha를 찾는 것과 동일. 위처럼 표현한 가중치 벡터에 데이터를 곱하면 아래와 같다.</p>

\[\mathbf{w^T z}=\sum_{i=1}{n}\alpha_i\mathbf{x_i^T z}\]

<p>위 식에서 \(\mathbf{x^T z}=k(\mathbf{x}, \mathbf{z})\)로 kernelize 할 수 있다. 그렇게 되면 아래 같이 정리된다.</p>

\[\vec{\alpha} = \mathbf{K^{-1}y}\]

<p>Ridge regression은 위와 유사한다.</p>

<p>*유사도라는 개념. w를 x의 선형 결합으로 표현한다는 것은 데이터 사이의 유사도 개념과 밀접하다. perceptron 예시 참고.</p>

<h2 id="kernel-pca">Kernel PCA</h2>]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="kernel" /><summary type="html"><![CDATA[Linear Regression with Non-linear Features]]></summary></entry><entry><title type="html">EM 알고리즘 공부하기</title><link href="http://localhost:4000/study/ml-dl/expectation-maximization/" rel="alternate" type="text/html" title="EM 알고리즘 공부하기" /><published>2023-04-18T00:00:00+09:00</published><updated>2023-04-18T00:00:00+09:00</updated><id>http://localhost:4000/study/ml-dl/expectation-maximization</id><content type="html" xml:base="http://localhost:4000/study/ml-dl/expectation-maximization/"><![CDATA[]]></content><author><name>bear11235</name></author><category term="study" /><category term="ML-DL" /><category term="study" /><category term="ML-DL" /><category term="EM" /><category term="GMM" /><summary type="html"><![CDATA[]]></summary></entry></feed>