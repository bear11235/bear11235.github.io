---
title: "t-SNE 공부하기"
categories:
  - study
  - machine learning
tags:
  - study
  - machine learning
---

# SNE
Stochastic Neighbor Embedding의 약자. 여기서 임베딩의 의미는 고차원에서 저차원으로 매핑한다는 말이다.

고차원 공간에 있는 데이터 포인트들 사이의 거리, 혹은 이웃인 정도를 확률로서 표현하고, 그 확률을 유지하도록 저차원 공간으로 매핑하는 것. 데이터 자체는 왜곡이 될 수 있지만, 데이터 사이의 가까운 정도는 최대한 유지하고 싶다. 여기서 학습이라는 것은 고차원 공간에서 저차원 공간으로 매핑하는 방법을 학습하는 것.

고차원에서 이웃의 정도를 결정하는 방법? -> Squared Exponential 함수를 통해 거리를 측정하고 확률로 표현하기 위해서 normalize를 진행한다. n개의 데이터 포인트에 대해서 각각 n개의 데이터에 대한 이웃인 정도를 나타내기에 n by n 형태의 Neighbar Probability Matrix가 생성된다. 각 데이터 포인트 사이의 절대적 거리는 대칭적이지만, 기준이 되는 포인트에서 normalization constant는 다르기 때문에, probability matrix는 비대칭으로 표현될 수 있다.

## Perplexity
2 ** H(P_i)로 정의된다. 데이터끼리 뭉치고 흩어지는 정도를 정하는 파라미터. 대략 한 점에서 이웃이라고 생각하는 점의 개수라고 생각하면 될 듯.

## Cost Function
고차원과 저차원에서의 확률 행렬을 각각 P_ij, Q_ij라고 하면, 그 둘 사이의 차이값, 거리값, 괴리감은 확률 분포의 괴리를 표현하는 KL divergence로 표현한다. J = KL(P||Q)